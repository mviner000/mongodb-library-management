if i can now get the short_names via "mongosh". we could also use that to show in our frontend.
my plan is to show the "Collection's column name's shortname instead of it's original name, make the fallback to orig name if it is null"

app_database> db.ui_metadata.find({}, { "ui.short_names": 1 }).pretty()
... 
[
  {
    _id: ObjectId('68021a642b527d4a363c1e59'),
    ui: {
      short_names: {
        username: 'username',
        email: 'email',
        password: 'password',
        is_archive: 'is_archive',
        pinned_by: 'pinned_by',
        row_height: 'row_height',
        created_at: 'created_at',
        updated_at: 'updated_at'
      }
    }
  },
  {
    _id: ObjectId('68021a642b527d4a363c1e5a'),
    ui: {
      short_names: {
        session_token: 'session_token',
        user_id: 'user_id',
        expires_at: 'expires_at',
        is_valid: 'is_valid',
        is_archive: 'is_archive',
        pinned_by: 'pinned_by',
        row_height: 'row_height',
        created_at: 'created_at',
        label: 'label'
      }
    }
  },
  {
    _id: ObjectId('68021a812b527d4a363c1e5b'),
    ui: {
      short_names: {
        school_id: 'school_id',
        first_name: 'first_name',
        middle_name: 'middle_name',
        last_name: 'last_name',
        gender: 'gender',
        course: 'course',
        department: 'department',
        position: 'position',
        major: 'major',
        year_level: 'year_level',
        is_active: 'is_active',
        last_updated_semester_id: 'last_updated_semester_id',
        is_archive: 'is_archive',
        pinned_by: 'pinned_by',
        row_height: 'row_height',
        created_at: 'created_at',
        updated_at: 'updated_at'
      }
    }
  },
  {
    _id: ObjectId('68021a812b527d4a363c1e5c'),
    ui: {
      short_names: {
        school_id: 'school_id',
        full_name: 'full_name',
        time_in_date: 'time_in_date',
        classification: 'classification',
        purpose_label: 'purpose_label',
        is_archive: 'is_archive',
        pinned_by: 'pinned_by',
        row_height: 'row_height',
        created_at: 'created_at',
        updated_at: 'updated_at'
      }
    }
  },
  {
    _id: ObjectId('68021a812b527d4a363c1e5d'),
    ui: {
      short_names: {
        label: 'label',
        icon_name: 'icon_name',
        is_deleted: 'is_deleted',
        is_archive: 'is_archive',
        pinned_by: 'pinned_by',
        row_height: 'row_height',
        created_at: 'created_at',
        updated_at: 'updated_at'
      }
    }
  },
  {
    _id: ObjectId('68021a812b527d4a363c1e5e'),
    ui: {
      short_names: {
        label: 'label',
        is_active: 'is_active',
        is_archive: 'is_archive',
        pinned_by: 'pinned_by',
        row_height: 'row_height',
        created_at: 'created_at',
        updated_at: 'updated_at'
      }
    }
  },
  {
    _id: ObjectId('68021a812b527d4a363c1e5f'),
    ui: {
      short_names: {
        component_name: 'component_name',
        tailwind_classes: 'tailwind_classes',
        label: 'label',
        is_archive: 'is_archive',
        pinned_by: 'pinned_by',
        row_height: 'row_height',
        created_at: 'created_at',
        updated_at: 'updated_at'
      }
    }
  }
]

console log also the short_names, when "MongoDBDataTable.vue" is loaded.
// src/lib_mongodb_schema.rs

use mongodb::{
    options::IndexOptions,
    Database,
    IndexModel,
};
use mongodb::bson::{doc, Document};
use anyhow::Result;
use crate::mongodb_schema::{
    create_archive_index, 
    create_pinned_index,
    merge_with_archive_pinned_and_row_height_properties
};

// Library-specific collection for school accounts
pub async fn create_lib_school_accounts_collection(db: &Database) -> Result<()> {
    let collection = db.collection::<Document>("school_accounts");
    
    // Create indexes
    let indexes = vec![
        IndexModel::builder()
            .keys(doc! { "school_id": 1 })
            .options(Some(mongodb::options::IndexOptions::builder()
                .unique(true)
                .build()))
            .build(),
        IndexModel::builder()
            .keys(doc! { "last_updated_semester_id": 1 })
            .options(Some(IndexOptions::builder()
                .name("semester_ref_idx".to_string())
                .build()))
            .build(),
        create_archive_index(),
        create_pinned_index(),
    ];
    
    collection.create_indexes(indexes, None).await?;
    
    // Define base properties for this collection
    let base_properties = doc! {
        "school_id": { "bsonType": "string", "description": "Unique school ID (required)" },
        "first_name": { "bsonType": "string", "description": "First name" },
        "middle_name": { "bsonType": "string", "description": "Middle name" },
        "last_name": { "bsonType": "string", "description": "Last name" },
        "gender": { "bsonType": "int", "description": "Gender (integer code)" },
        "course": { "bsonType": "string", "description": "Course" },
        "department": { "bsonType": "string", "description": "Department" },
        "position": { "bsonType": "string", "description": "Position" },
        "major": { "bsonType": "string", "description": "Major" },
        "year_level": { "bsonType": "string", "description": "Year level" },
        "is_active": { "bsonType": "bool", "description": "Active status flag (required)" },
        "last_updated_semester_id": { "bsonType": "string", "description": "REF:semesters | Reference to last updated semester" },
        "created_at": { "bsonType": "date", "description": "Creation timestamp (required)" },
        "updated_at": { "bsonType": "date", "description": "Last update timestamp (required)" }
    };
    
    // Merge with both archive and pinned properties
    let properties = merge_with_archive_pinned_and_row_height_properties(base_properties);
    
    // Apply validator schema using collMod
    db.run_command(
        doc! {
            "collMod": "school_accounts",
            "validator": {
                "$jsonSchema": {
                    "bsonType": "object",
                    "required": ["school_id", "is_active", "created_at"],
                    "properties": properties
                }
            },
            "validationLevel": "moderate",
            "validationAction": "error"
        },
        None
    ).await?;
    
    Ok(())
}

// Library-specific collection for attendance records
pub async fn create_lib_attendance_collection(db: &Database) -> Result<()> {
    let collection = db.collection::<Document>("attendance");
    
    // Create indexes
    let indexes = vec![
        IndexModel::builder()
            .keys(doc! { "school_id": 1, "time_in_date": 1 })
            .options(Some(IndexOptions::builder()
                .unique(true)
                .build()))
            .build(),
        IndexModel::builder()
            .keys(doc! { "time_in_date": 1 })
            .build(),
        create_archive_index(),
        create_pinned_index(),
    ];
    
    collection.create_indexes(indexes, None).await?;
    
    // Define base properties for this collection
    let base_properties = doc! {
        "school_id": { "bsonType": "string", "description": "School ID (required)" },
        "full_name": { "bsonType": "string", "description": "Full name of the person (required)" },
        "time_in_date": { "bsonType": "date", "description": "Date and time of entry (required)" },
        "classification": { "bsonType": "string", "description": "Classification (required)" },
        "purpose_label": { "bsonType": "string", "description": "Purpose label" },
        "created_at": { "bsonType": "date", "description": "Creation timestamp (required)" },
        "updated_at": { "bsonType": "date", "description": "Last update timestamp (required)" }
    };
    
    // Merge with both archive and pinned properties
    let properties = merge_with_archive_pinned_and_row_height_properties(base_properties);
    
    // Apply validator schema using collMod
    db.run_command(
        doc! {
            "collMod": "attendance",
            "validator": {
                "$jsonSchema": {
                    "bsonType": "object",
                    "required": ["school_id", "full_name", "classification", "created_at"],
                    "properties": properties
                }
            },
            "validationLevel": "moderate",
            "validationAction": "error"
        },
        None
    ).await?;
    
    Ok(())
}

// Library-specific collection for purposes
pub async fn create_lib_purposes_collection(db: &Database) -> Result<()> {
    let collection = db.collection::<Document>("purposes");
    
    // Create indexes
    let indexes = vec![
        IndexModel::builder()
            .keys(doc! { "label": 1 })
            .options(Some(mongodb::options::IndexOptions::builder()
                .unique(true)
                .build()))
            .build(),
        create_archive_index(),
        create_pinned_index(),
    ];
    
    collection.create_indexes(indexes, None).await?;
    
    // Define base properties for this collection
    let base_properties = doc! {
        "label": { "bsonType": "string", "description": "Purpose label (required, unique)" },
        "icon_name": { "bsonType": "string", "description": "Icon name (required)" },
        "is_deleted": { "bsonType": "bool", "description": "Deletion flag (required)" },
        "created_at": { "bsonType": "date", "description": "Creation timestamp (required)" },
        "updated_at": { "bsonType": "date", "description": "Last update timestamp (required)" }
    };
    
    // Merge with both archive and pinned properties
    let properties = merge_with_archive_pinned_and_row_height_properties(base_properties);
    
    // Apply validator schema using collMod
    db.run_command(
        doc! {
            "collMod": "purposes",
            "validator": {
                "$jsonSchema": {
                    "bsonType": "object",
                    "required": ["label", "icon_name", "is_deleted", "created_at"],
                    "properties": properties
                }
            },
            "validationLevel": "moderate",
            "validationAction": "error"
        },
        None
    ).await?;
    
    Ok(())
}

// Library-specific collection for semesters
pub async fn create_lib_semesters_collection(db: &Database) -> Result<()> {
    let collection = db.collection::<Document>("semesters");
    
    // Create indexes
    let indexes = vec![
        IndexModel::builder()
            .keys(doc! { "label": 1 })
            .options(Some(IndexOptions::builder()
                .unique(true)
                .build()))
            .build(),
        create_archive_index(),
        create_pinned_index(),
    ];
    
    collection.create_indexes(indexes, None).await?;
    
    // Define base properties for this collection
    let base_properties = doc! {
        "label": { "bsonType": "string", "description": "Unique label for the semester (required)" },
        "is_active": { "bsonType": "bool", "description": "Indicates if this is the active semester (required)" },
        "created_at": { "bsonType": "date", "description": "Creation timestamp (required)" },
        "updated_at": { "bsonType": "date", "description": "Last update timestamp (required)" }
    };
    
    // Merge with both archive and pinned properties
    let properties = merge_with_archive_pinned_and_row_height_properties(base_properties);
    
    // Apply validator schema using collMod
    db.run_command(
        doc! {
            "collMod": "semesters",
            "validator": {
                "$jsonSchema": {
                    "bsonType": "object",
                    "required": ["label", "is_active", "created_at"],
                    "properties": properties
                }
            },
            "validationLevel": "moderate",
            "validationAction": "error"
        },
        None
    ).await?;
    
    Ok(())
}

// Library-specific collection for settings styles
pub async fn create_lib_settings_styles_collection(db: &Database) -> Result<()> {
    let collection = db.collection::<Document>("settings_styles");
    
    // Create indexes
    let indexes = vec![
        IndexModel::builder()
            .keys(doc! { "component_name": 1 })
            .options(Some(IndexOptions::builder()
                .unique(true)  // Add unique constraint here
                .build()))
            .build(),
        create_archive_index(),
        create_pinned_index(),
    ];
    
    collection.create_indexes(indexes, None).await?;
    
    // Define base properties for this collection
    let base_properties = doc! {
        "component_name": { "bsonType": "string", "description": "Component name (required)" },
        "tailwind_classes": { "bsonType": "string", "description": "Tailwind CSS classes (required)" },
        "label": { "bsonType": "string", "description": "Optional label" },
        "created_at": { "bsonType": "date", "description": "Creation timestamp (required)" },
        "updated_at": { "bsonType": "date", "description": "Last update timestamp (required)" }
    };
    
    // Merge with both archive and pinned properties
    let properties = merge_with_archive_pinned_and_row_height_properties(base_properties);
    
    // Apply validator schema using collMod
    db.run_command(
        doc! {
            "collMod": "settings_styles",
            "validator": {
                "$jsonSchema": {
                    "bsonType": "object",
                    "required": ["component_name", "tailwind_classes", "created_at"],
                    "properties": properties
                }
            },
            "validationLevel": "moderate",
            "validationAction": "error"
        },
        None
    ).await?;
    
    Ok(())
}

// Additional helper function for UI metadata for library collections
pub fn get_default_lib_column_widths(collection_name: &str) -> Document {
    let default_column_width = 200;
    
    match collection_name {
        "school_accounts" => doc! {
            "school_id": default_column_width,
            "first_name": default_column_width,
            "middle_name": default_column_width,
            "last_name": default_column_width,
            "gender": default_column_width,
            "course": default_column_width,
            "department": default_column_width,
            "position": default_column_width,
            "major": default_column_width,
            "year_level": default_column_width,
            "is_active": default_column_width,
            "last_updated_semester_id": default_column_width,
            "is_archive": default_column_width,
            "pinned_by": default_column_width,
            "row_height": default_column_width,
            "created_at": default_column_width,
            "updated_at": default_column_width
        },
        "attendance" => doc! {
            "school_id": default_column_width,
            "full_name": default_column_width,
            "time_in_date": default_column_width,
            "classification": default_column_width,
            "purpose_label": default_column_width,
            "is_archive": default_column_width,
            "pinned_by": default_column_width,
            "row_height": default_column_width,
            "created_at": default_column_width,
            "updated_at": default_column_width
        },
        "purposes" => doc! {
            "label": default_column_width,
            "icon_name": default_column_width,
            "is_deleted": default_column_width,
            "is_archive": default_column_width,
            "pinned_by": default_column_width,
            "row_height": default_column_width,
            "created_at": default_column_width,
            "updated_at": default_column_width
        },
        "semesters" => doc! {
            "label": default_column_width,
            "is_active": default_column_width,
            "is_archive": default_column_width,
            "pinned_by": default_column_width,
            "row_height": default_column_width,
            "created_at": default_column_width,
            "updated_at": default_column_width
        },
        "settings_styles" => doc! {
            "component_name": default_column_width,
            "tailwind_classes": default_column_width,
            "label": default_column_width,
            "is_archive": default_column_width,
            "pinned_by": default_column_width,
            "row_height": default_column_width,
            "created_at": default_column_width,
            "updated_at": default_column_width
        },
        _ => doc! {}
    }
}

// Helper function to get default sort field for library collections
pub fn get_default_lib_sort_field(collection_name: &str) -> &str {
    match collection_name {
        "school_accounts" => "school_id",
        "attendance" => "time_in_date",
        "purposes" => "label",
        "semesters" => "label",
        "settings_styles" => "component_name",
        _ => "created_at",
    }
}

// Initialize all library collections
pub async fn initialize_all_library_collections(db: &Database) -> Result<()> {
    create_lib_school_accounts_collection(db).await?;
    create_lib_attendance_collection(db).await?;
    create_lib_purposes_collection(db).await?;
    create_lib_semesters_collection(db).await?;
    create_lib_settings_styles_collection(db).await?;
    
    // Create UI metadata for these collections
    create_lib_ui_metadata(db).await?;
    
    Ok(())
}

// Helper function to create UI metadata for library collections
async fn create_lib_ui_metadata(db: &Database) -> Result<()> {
    let collection = db.collection::<Document>("ui_metadata");
    let now = mongodb::bson::DateTime::now();
    
    // Library collections
    let lib_collections = vec![
        "school_accounts",
        "attendance",
        "purposes",
        "semesters",
        "settings_styles",
    ];
    
    for collection_name in lib_collections {
        // Get column widths for this collection
        let column_widths = get_default_lib_column_widths(collection_name);
        
        // Create column order
        let column_order = mongodb::bson::to_bson(&column_widths.keys().collect::<Vec<_>>())
            .unwrap_or(mongodb::bson::Bson::Array(Vec::new()));
        
        // Create default short names (same as original field names)
        let mut short_names = Document::new();
        for key in column_widths.keys() {
            short_names.insert(key.clone(), key.clone());
        }
        
        let default_settings = doc! {
            "collection": collection_name,
            "ui": {
                "columnWidths": column_widths,
                "columnOrder": column_order,
                "hiddenColumns": [],
                "sortSettings": {
                    "field": get_default_lib_sort_field(collection_name),
                    "direction": "asc"
                },
                "filterSettings": {},
                "short_names": short_names
            },
            "created_at": now,
            "updated_at": now
        };
        
        // Use upsert to create only if not exists
        let filter = doc! {
            "collection": collection_name,
            "user_id": { "$exists": false }  // Global defaults have no user_id
        };
        
        collection.update_one(
            filter,
            doc! { "$setOnInsert": default_settings },
            mongodb::options::UpdateOptions::builder()
                .upsert(true)
                .build(),
        ).await?;
    }
    
    Ok(())
}

// src/mongodb_schema.rs
use mongodb::{
    options::IndexOptions,
    Database,
    IndexModel,
};
use std::time::Duration;
use mongodb::bson::{doc, Document};
use anyhow::Result;
use crate::lib_mongodb_schema;

// NOTE:
// row height is used for each data[a more data specific approach], unlike column width that has a global state

pub async fn initialize_database(db: &Database) -> Result<()> {
    // Create only essential collections by default
    create_users_collection(db).await?;
    create_sessions_collection(db).await?;
    create_ui_metadata_collection(db).await?;

    // Note: library-specific collections are now moved to lib_mongodb_schema.rs
    // and can be created separately when needed

    Ok(())
}

// Helper function to get archive properties schema to be reused - made public
pub fn get_archive_properties() -> Document {
    doc! {
        "is_archive": { 
            "bsonType": "bool", 
            "description": "Flag indicating if the document is archived (true) or active (false)" 
        },
        "archive_history": {
            "bsonType": "array",
            "description": "Log of archive and recovery actions",
            "items": {
                "bsonType": "object",
                "required": ["action", "user_id", "timestamp"],
                "properties": {
                    "action": { 
                        "bsonType": "string", 
                        "enum": ["archive", "recover"], 
                        "description": "The action performed" 
                    },
                    "user_id": { 
                        "bsonType": "objectId", 
                        "description": "REF:users | ID of the user performing the action" 
                    },
                    "timestamp": { 
                        "bsonType": "date", 
                        "description": "Timestamp of the action" 
                    }
                }
            }
        }
    }
}

// Helper function to get pinned properties schema to be reused - made public
pub fn get_pinned_properties() -> Document {
    doc! {
        "pinned_by": {
            "bsonType": "array",
            "description": "Array of user IDs who pinned this document",
            "items": { "bsonType": "string" }
        },
        "pinned_history": {
            "bsonType": "array",
            "description": "Log of pin/unpin actions",
            "items": {
                "bsonType": "object",
                "required": ["action", "user_id", "timestamp"],
                "properties": {
                    "action": { 
                        "bsonType": "string", 
                        "enum": ["pin", "unpin"] 
                    },
                    "user_id": { "bsonType": "string" },
                    "timestamp": { "bsonType": "date" }
                }
            }
        }
    }
}

// New helper function to get row_height properties schema
pub fn get_row_height_properties() -> Document {
    doc! {
        "row_height": { 
            "bsonType": "int", 
            "description": "Maximum usage limit for this document, initially set to 20" 
        }
    }
}

// Helper function to create archive index - made public
pub fn create_archive_index() -> IndexModel {
    IndexModel::builder()
        .keys(doc! { "is_archive": 1 })
        .build()
}

// Helper function to create pinned index - made public
pub fn create_pinned_index() -> IndexModel {
    IndexModel::builder()
        .keys(doc! { "pinned_by": 1 })
        .build()
}

// Helper function to merge document properties with archive properties - made public
pub fn merge_with_archive_properties(properties: Document) -> Document {
    let mut merged = properties;
    for (key, value) in get_archive_properties() {
        merged.insert(key, value);
    }
    merged
}

// Helper function to merge document properties with pinned properties - made public
pub fn merge_with_pinned_properties(properties: Document) -> Document {
    let mut merged = properties;
    for (key, value) in get_pinned_properties() {
        merged.insert(key, value);
    }
    merged
}

// Helper function to merge document properties with both archive and pinned properties - made public
pub fn merge_with_archive_pinned_and_row_height_properties(properties: Document) -> Document {
    let with_archive = merge_with_archive_properties(properties);
    let with_pinned = merge_with_pinned_properties(with_archive);
    
    // Add row_height property to all collections with pinned_by
    let mut merged = with_pinned;
    for (key, value) in get_row_height_properties() {
        merged.insert(key, value);
    }
    merged
}

async fn create_users_collection(db: &Database) -> Result<()> {
    let collection = db.collection::<Document>("users");

    // Create a unique index on "username"
    let username_index = IndexModel::builder()
        .keys(doc! { "username": 1 })
        .options(Some(mongodb::options::IndexOptions::builder()
            .unique(true)
            .build()))
        .build();

    // Create a unique index on "email"
    let email_index = IndexModel::builder()
        .keys(doc! { "email": 1 })
        .options(Some(mongodb::options::IndexOptions::builder()
            .unique(true)
            .build()))
        .build();

    // Add archive index
    let archive_index = create_archive_index();
    
    // Add pinned index
    let pinned_index = create_pinned_index();

    collection.create_index(username_index, None).await?;
    collection.create_index(email_index, None).await?;
    collection.create_index(archive_index, None).await?;
    collection.create_index(pinned_index, None).await?;

    // Define base properties for this collection
    let base_properties = doc! {
        "username": {
            "bsonType": "string",
            "description": "Username (required, unique)"
        },
        "email": {
            "bsonType": "string",
            "pattern": "^[\\w.-]+@[\\w.-]+\\.[a-zA-Z]{2,}$",
            "description": "Email (required, unique, must match pattern)"
        },
        "password": {
            "bsonType": "string",
            "description": "Password (hashed, required)"
        },
        "created_at": {
            "bsonType": "date",
            "description": "Creation timestamp (required)"
        },
        "updated_at": {
            "bsonType": "date", 
            "description": "Last update timestamp (required)"
        }
    };
    
    // Merge with archive, pinned, and row_height properties
    let properties = merge_with_archive_pinned_and_row_height_properties(base_properties);

    // Apply validator schema using collMod
    db.run_command(
        doc! {
            "collMod": "users",
            "validator": {
                "$jsonSchema": {
                    "bsonType": "object",
                    "required": ["username", "email", "password", "created_at"],
                    "properties": properties
                }
            },
            "validationLevel": "moderate",
            "validationAction": "error"
        },
        None
    ).await?;

    Ok(())
}

async fn create_sessions_collection(db: &Database) -> Result<()> {
    let collection = db.collection::<Document>("sessions");
    
    // Create indexes
    let indexes = vec![
        IndexModel::builder()
            .keys(doc! { "session_token": 1 })
            .options(Some(IndexOptions::builder()
                .unique(true)
                .build()))
            .build(),
        IndexModel::builder()
            .keys(doc! { "user_id": 1 })
            .build(),
        IndexModel::builder()
            .keys(doc! { "expires_at": 1 })
            .options(Some(IndexOptions::builder()
                .expire_after(Some(Duration::from_secs(0))) // TTL index (expire after 0 seconds)
                .build()))
            .build(),
        // Add archive index
        create_archive_index(),
        // Add pinned index
        create_pinned_index(),
    ];

    collection.create_indexes(indexes, None).await?;
    
    // Define base properties for this collection
    let base_properties = doc! {
        "session_token": { 
            "bsonType": "string", 
            "description": "Unique session token (required)" 
        },
        "user_id": { 
            "bsonType": "string", 
            "description": "REF:users | Reference to user (required)" 
        },
        "expires_at": { 
            "bsonType": "date", 
            "description": "Expiration timestamp (required)" 
        },
        "is_valid": { 
            "bsonType": "bool", 
            "description": "Validity status (required)" 
        },
        "created_at": { 
            "bsonType": "date", 
            "description": "Creation timestamp (required)" 
        },
        "label": {
            "bsonType": "string",
            "description": "Session label (required)"
        }
    };
    
    // Merge with archive, pinned, and row_height properties
    let properties = merge_with_archive_pinned_and_row_height_properties(base_properties);
    
    // Apply validator schema using collMod
    db.run_command(
        doc! {
            "collMod": "sessions",
            "validator": {
                "$jsonSchema": {
                    "bsonType": "object",
                    "required": ["session_token", "user_id", "expires_at", "is_valid", "created_at", "label"],
                    "properties": properties
                }
            },
            "validationLevel": "moderate",
            "validationAction": "error"
        },
        None
    ).await?;
    
    Ok(())
}

// Keep the ui_metadata collection as is - no changes per requirements
async fn create_ui_metadata_collection(db: &Database) -> Result<()> {
    let collection = db.collection::<Document>("ui_metadata");
    
    // Create indexes for faster lookups
    let indexes = vec![
        IndexModel::builder()
            .keys(doc! { "collection": 1, "user_id": 1 })
            .options(Some(IndexOptions::builder()
                .unique(true)
                .build()))
            .build(),
    ];

    collection.create_indexes(indexes, None).await?;
    
    // Apply validator schema using collMod
    db.run_command(
        doc! {
            "collMod": "ui_metadata",
            "validator": {
                "$jsonSchema": {
                    "bsonType": "object",
                    "required": ["collection", "ui", "created_at"],
                    "properties": {
                        "collection": { "bsonType": "string", "description": "Collection name" },
                        "ui": { 
                            "bsonType": "object", 
                            "properties": {
                                "columnWidths": { "bsonType": "object", "description": "Width for each column" },
                                "columnOrder": { "bsonType": "array", "description": "Order of columns in the view" },
                                "hiddenColumns": { "bsonType": "array", "description": "List of hidden columns" },
                                "sortSettings": { 
                                    "bsonType": "object", 
                                    "properties": {
                                        "field": { "bsonType": "string" },
                                        "direction": { "bsonType": "string", "enum": ["asc", "desc"] }
                                    }
                                },
                                "filterSettings": { "bsonType": "object", "description": "Filter configurations" },
                                "short_names": { "bsonType": "object", "description": "Short display names for columns" }
                            }
                        },
                        "created_at": { "bsonType": "date", "description": "Creation timestamp" },
                        "updated_at": { "bsonType": "date", "description": "Last update timestamp" }
                    }
                }
            },
            "validationLevel": "moderate",
            "validationAction": "error"
        },
        None
    ).await?;

    // Insert default global settings for each collection
    let default_settings = create_default_ui_settings();
    
    for setting in default_settings {
        // Use upsert with $setOnInsert to create only if not exists
        let filter = doc! {
            "collection": setting.get("collection").unwrap(),
            "user_id": { "$exists": false }  // Global defaults have no user_id
        };
        
        collection.update_one(
            filter,
            doc! { "$setOnInsert": setting },  // Only apply settings when inserting a new document
            mongodb::options::UpdateOptions::builder()
                .upsert(true)
                .build(),
        ).await?;
    }

    Ok(())
}

// metadata for collections start here
// Keep the UI metadata helper functions as is, but update collection list to include only essential collections
const DEFAULT_COLUMN_WIDTH: i32 = 200;

fn create_default_ui_settings() -> Vec<Document> {
    // Include only essential collections
    let collections = vec![
        "users",
        "sessions",
    ];
    
    let now = mongodb::bson::DateTime::now();
    
    collections.iter().map(|&collection_name| {
        // Get field names for this collection to create column width settings
        let column_widths = get_default_column_widths(collection_name);

        // Ensure the backend only stores data column widths (excluding the _actions and _row_number columns)
        let mut filtered_column_widths = Document::new();
        for (key, value) in column_widths.iter() {
            if !["_row_number", "_actions"].contains(&key.as_str()) {
                filtered_column_widths.insert(key.clone(), value.clone());
            }
        }

        // Create column order based on fields (same order as in schema)
        let column_order = mongodb::bson::to_bson(&column_widths.keys().collect::<Vec<_>>())
            .unwrap_or(mongodb::bson::Bson::Array(Vec::new()));
        
        // Create default short names (same as original field names)
        let mut short_names = Document::new();
        for key in column_widths.keys() {
            short_names.insert(key.clone(), key.clone());
        }
        
        doc! {
            "collection": collection_name,
            "ui": {
                "columnWidths": column_widths,
                "columnOrder": column_order,
                "hiddenColumns": [],
                "sortSettings": {
                    "field": get_default_sort_field(collection_name),
                    "direction": "asc"
                },
                "filterSettings": {},
                "short_names": short_names
            },
            "created_at": now,
            "updated_at": now
        }
    }).collect()
}

fn get_default_column_widths(collection_name: &str) -> Document {
    match collection_name {
        "users" => doc! {
            "username": DEFAULT_COLUMN_WIDTH, 
            "email": DEFAULT_COLUMN_WIDTH, 
            "password": DEFAULT_COLUMN_WIDTH,
            "is_archive": DEFAULT_COLUMN_WIDTH,
            "pinned_by": DEFAULT_COLUMN_WIDTH,
            "row_height": DEFAULT_COLUMN_WIDTH,
            "created_at": DEFAULT_COLUMN_WIDTH, 
            "updated_at": DEFAULT_COLUMN_WIDTH
        },
        "sessions" => doc! {
            "session_token": DEFAULT_COLUMN_WIDTH, 
            "user_id": DEFAULT_COLUMN_WIDTH, 
            "expires_at": DEFAULT_COLUMN_WIDTH,
            "is_valid": DEFAULT_COLUMN_WIDTH,
            "is_archive": DEFAULT_COLUMN_WIDTH,
            "pinned_by": DEFAULT_COLUMN_WIDTH,
            "row_height": DEFAULT_COLUMN_WIDTH,
            "created_at": DEFAULT_COLUMN_WIDTH, 
            "label": DEFAULT_COLUMN_WIDTH
        },
        _ => {
            let field_names = get_field_names_for_collection(collection_name);
            let mut widths = Document::new();
            for field in field_names {
                widths.insert(field, DEFAULT_COLUMN_WIDTH);
            }
            widths
        }
    }
}

fn get_default_sort_field(collection_name: &str) -> &str {
    match collection_name {
        "users" => "username",
        "sessions" => "created_at",
        _ => "created_at",
    }
}

// Helper function to get field names for a collection - reduced to essential collections
fn get_field_names_for_collection(collection_name: &str) -> Vec<&str> {
    // Add is_archive, pinned_by, and row_height to all collection field lists
    let mut fields = match collection_name {
        "users" => vec![
            "username", "email", "password", "created_at", "updated_at"
        ],
        "sessions" => vec![
            "session_token", "user_id", "expires_at", "is_valid", "created_at", "label"
        ],
        _ => vec!["created_at", "updated_at"] // Fallback for unknown collections
    };
    
    // Add is_archive, pinned_by, and row_height fields to each collection's fields
    fields.push("is_archive");
    fields.push("pinned_by");
    fields.push("row_height");
    fields
}
// metadata for collections ends here

// Public function to initialize all library collections if needed
pub async fn initialize_library_collections(db: &Database) -> Result<()> {
    // Call the library-specific initialization
    lib_mongodb_schema::initialize_all_library_collections(db).await?;
    Ok(())
}
// src/api_server/handlers/collection_handlers.rs

use axum::{
    http::StatusCode,
    Json,
    extract::{State, Path},
    response::IntoResponse,
};
use std::sync::Arc;
use tokio::sync::Mutex;

use mongodb::Database;
use mongodb::bson::{doc, Document};
use anyhow::Result;
use std::collections::HashSet;
use futures_util::stream::StreamExt;

use crate::api_server::state::ApiServerState;
use crate::api_server::models::{ApiResponse, error_response};
use crate::api_server::services::database_service::get_database;
use crate::api_server::services::get_collection_schema_with_ui;
use crate::api_server::services::update_ui_metadata;

// Collection handlers
pub async fn list_collections_handler(
    State(state): State<Arc<Mutex<ApiServerState>>>
) -> impl IntoResponse {
    let mongodb_state = &state.lock().await.mongodb_state;
    
    match get_database(mongodb_state).await {
        Ok(db) => {
            match db.list_collection_names(None).await {
                Ok(collections) => {
                    (StatusCode::OK, Json(ApiResponse {
                        success: true,
                        data: Some(collections),
                        error: None,
                    }))
                },
                Err(e) => error_response::<Vec<String>>(StatusCode::INTERNAL_SERVER_ERROR, e.to_string()),
            }
        },
        Err((status, e)) => error_response::<Vec<String>>(status, e),
    }
}


pub async fn get_required_and_unique_fields(db: &Database, coll_name: &str) -> Result<Vec<String>, mongodb::error::Error> {
    // Retrieve collection information to extract required fields
    let coll_info = db.run_command(doc! {
        "listCollections": 1,
        "filter": { "name": coll_name },
        "nameOnly": false,
    }, None).await?;

    let required_fields = extract_required_fields(&coll_info).unwrap_or_default();

    // Retrieve all indexes for the collection
    let mut cursor = db.collection::<Document>(coll_name).list_indexes(None).await?;

    // Collect all fields from unique indexes
    let mut unique_fields = HashSet::new();
    
    // Use StreamExt to iterate over the cursor asynchronously
    while let Some(index_result) = cursor.next().await {
        if let Ok(index) = index_result {
            // Check if this index is unique
            if index.options.as_ref().and_then(|opts| opts.unique).unwrap_or(false) {
                // Extract the key fields from this unique index
                for (field, _) in index.keys.iter() {
                    unique_fields.insert(field.clone());
                }
            }
        }
    }

    // Find intersection of required and unique fields
    let result: Vec<String> = required_fields.into_iter()
        .filter(|field| unique_fields.contains(field))
        .collect();

    Ok(result)
}

fn extract_required_fields(coll_info: &Document) -> Option<Vec<String>> {
    let cursor = coll_info.get_document("cursor").ok()?;
    let first_batch = cursor.get_array("firstBatch").ok()?;
    let coll_doc = first_batch.first()?.as_document()?;
    let options = coll_doc.get_document("options").ok()?;
    let validator = options.get_document("validator").ok()?;
    let json_schema = validator.get_document("$jsonSchema").ok()?;
    let required = json_schema.get_array("required").ok()?;

    Some(required.iter()
        .filter_map(|v| v.as_str().map(|s| s.to_string()))
        .collect())
}

pub async fn get_collection_schema_handler(
    State(state): State<Arc<Mutex<ApiServerState>>>,
    Path(collection_name): Path<String>,
) -> impl IntoResponse {
    let mongodb_state = &state.lock().await.mongodb_state;
    
    match get_database(mongodb_state).await {
        Ok(db) => {
            // Get the schema with UI metadata
            let schema_result = get_collection_schema_with_ui(&db, &collection_name).await;
            
            // Get the required and unique fields
            let required_unique_result = get_required_and_unique_fields(&db, &collection_name).await;
            
            match (schema_result, required_unique_result) {
                (Ok(mut merged_schema), Ok(required_unique_fields)) => {
                    // Add the first required and unique field to the schema (if any exists)
                    let primary_key = required_unique_fields.first().cloned();
                    
                    // Insert the primary key into the merged schema
                    merged_schema.insert("primaryKey", bson::to_bson(&primary_key).unwrap_or(bson::Bson::Null));
                    
                    // Convert merged schema to JSON
                    match bson::from_bson(bson::Bson::Document(merged_schema)) {
                        Ok(merged_schema_json) => {
                            (StatusCode::OK, Json(ApiResponse {
                                success: true,
                                data: Some(merged_schema_json),
                                error: None,
                            }))
                        },
                        Err(e) => error_response::<serde_json::Value>(
                            StatusCode::INTERNAL_SERVER_ERROR, 
                            format!("Failed to convert merged schema to JSON: {}", e)
                        ),
                    }
                },
                (Ok(_), Err(e)) => error_response::<serde_json::Value>(
                    StatusCode::INTERNAL_SERVER_ERROR, 
                    format!("Failed to get required and unique fields: {}", e)
                ),
                (Err(e), _) => error_response::<serde_json::Value>(
                    StatusCode::INTERNAL_SERVER_ERROR, 
                    e
                ),
            }
        },
        Err((status, e)) => error_response::<serde_json::Value>(status, e),
    }
}

pub async fn update_ui_metadata_handler(
    State(state): State<Arc<Mutex<ApiServerState>>>,
    Path(collection_name): Path<String>,
    Json(payload): Json<serde_json::Value>,
) -> impl IntoResponse {
    let mongodb_state = &state.lock().await.mongodb_state;
    let db = match get_database(mongodb_state).await {
        Ok(db) => db,
        Err((status, e)) => return error_response::<()>(status, e),
    };

    // Extract column widths from payload
    let column_widths = match payload.get("columnWidths")
        .and_then(|v| v.as_object()) {
        Some(widths) => serde_json::Value::Object(widths.clone()),
        None => return error_response::<()>(StatusCode::BAD_REQUEST, "Invalid columnWidths format".into()),
    };

    // Use the service function instead of duplicating logic
    match update_ui_metadata(&db, &collection_name, &column_widths).await {
        Ok(_) => (StatusCode::OK, Json(ApiResponse {
            success: true,
            data: None,
            error: None,
        })),
        Err(e) => error_response::<()>(StatusCode::INTERNAL_SERVER_ERROR, e),
    }
}
// src/api_server/handlers/document_handlers.rs

use axum::{
    http::StatusCode,
    Json, 
    extract::{State, Path, Query},
    response::IntoResponse,
};
use axum_extra::{
    headers::{Authorization, authorization::Bearer},
    TypedHeader,
};
use mongodb::{
    bson::{doc, Document, oid::ObjectId}, 
    Cursor
};
use mongodb::options::{FindOneAndUpdateOptions, ReturnDocument};
use serde_json::json;
use std::sync::Arc;
use tokio::sync::Mutex;
use futures_util::StreamExt;
use std::collections::HashMap;
use chrono;

use crate::api_server::services::schema_service::get_collection_schema_internal;
use crate::api_server::state::ApiServerState;
use crate::api_server::models::{
    ApiResponse, InsertResponse, UpdateResponse, DeleteResponse, 
    error_response
};
use crate::api_server::services::database_service::{
    get_database, process_document_fields
};

// Document handlers
pub async fn find_documents_handler(
    State(state): State<Arc<Mutex<ApiServerState>>>,
    Path(collection_name): Path<String>,
    Query(params): Query<HashMap<String, String>>,
) -> impl IntoResponse {
    let mongodb_state = &state.lock().await.mongodb_state;
    
    // Extract filter from query parameters - fixed temporary value issue
    let filter_str = params.get("filter").cloned().unwrap_or_else(|| String::from("{}"));
    
    // Parse the JSON string into a Document
    let filter: Document = match serde_json::from_str(&filter_str) {
        Ok(f) => f,
        Err(e) => return error_response::<Vec<Document>>(
            StatusCode::BAD_REQUEST, 
            format!("Invalid filter JSON: {}", e)
        ),
    };
    
    match get_database(mongodb_state).await {
        Ok(db) => {
            let collection = db.collection::<Document>(&collection_name);
            
            match collection.find(filter, None).await {
                Ok(cursor) => {
                    match process_cursor(cursor).await {
                        Ok(documents) => {
                            (StatusCode::OK, Json(ApiResponse {
                                success: true,
                                data: Some(documents),
                                error: None,
                            }))
                        },
                        Err(e) => error_response::<Vec<Document>>(StatusCode::INTERNAL_SERVER_ERROR, e),
                    }
                },
                Err(e) => error_response::<Vec<Document>>(StatusCode::INTERNAL_SERVER_ERROR, e.to_string()),
            }
        },
        Err((status, e)) => error_response::<Vec<Document>>(status, e),
    }
}

pub async fn find_archived_documents_handler(
    State(state): State<Arc<Mutex<ApiServerState>>>,
    Path(collection_name): Path<String>,
    Query(params): Query<HashMap<String, String>>,
) -> impl IntoResponse {
    let mongodb_state = &state.lock().await.mongodb_state;
    
    let filter_str = params.get("filter").cloned().unwrap_or_else(|| String::from("{}"));
    
    let mut filter: Document = match serde_json::from_str(&filter_str) {
        Ok(f) => f,
        Err(e) => return error_response::<Vec<Document>>(
            StatusCode::BAD_REQUEST, 
            format!("Invalid filter JSON: {}", e)
        ),
    };
    
    // Filter for archived documents
    filter.insert("is_archive", true);
    
    match get_database(mongodb_state).await {
        Ok(db) => {
            let collection = db.collection::<Document>(&collection_name);
            
            match collection.find(filter, None).await {
                Ok(cursor) => {
                    match process_cursor(cursor).await {
                        Ok(documents) => {
                            (StatusCode::OK, Json(ApiResponse {
                                success: true,
                                data: Some(documents),
                                error: None,
                            }))
                        },
                        Err(e) => error_response::<Vec<Document>>(StatusCode::INTERNAL_SERVER_ERROR, e),
                    }
                },
                Err(e) => error_response::<Vec<Document>>(StatusCode::INTERNAL_SERVER_ERROR, e.to_string()),
            }
        },
        Err((status, e)) => error_response::<Vec<Document>>(status, e),
    }
}

pub async fn find_recovered_documents_handler(
    State(state): State<Arc<Mutex<ApiServerState>>>,
    Path(collection_name): Path<String>,
    Query(params): Query<HashMap<String, String>>,
) -> impl IntoResponse {
    let mongodb_state = &state.lock().await.mongodb_state;
    
    let filter_str = params.get("filter").cloned().unwrap_or_else(|| String::from("{}"));
    
    let mut filter: Document = match serde_json::from_str(&filter_str) {
        Ok(f) => f,
        Err(e) => return error_response::<Vec<Document>>(
            StatusCode::BAD_REQUEST, 
            format!("Invalid filter JSON: {}", e)
        ),
    };
    
    // Correctly filter for documents where the latest archive action is "recover"
    filter.insert("is_archive", false);
    filter.insert("$expr", doc! {
        "$eq": [
            { "$arrayElemAt": ["$archive_history.action", -1] },
            "recover"
        ]
    });
    
    match get_database(mongodb_state).await {
        Ok(db) => {
            let collection = db.collection::<Document>(&collection_name);
            
            match collection.find(filter, None).await {
                Ok(cursor) => {
                    match process_cursor(cursor).await {
                        Ok(documents) => {
                            (StatusCode::OK, Json(ApiResponse {
                                success: true,
                                data: Some(documents),
                                error: None,
                            }))
                        },
                        Err(e) => error_response::<Vec<Document>>(StatusCode::INTERNAL_SERVER_ERROR, e),
                    }
                },
                Err(e) => error_response::<Vec<Document>>(StatusCode::INTERNAL_SERVER_ERROR, e.to_string()),
            }
        },
        Err((status, e)) => error_response::<Vec<Document>>(status, e),
    }
}

pub async fn find_empty_archive_history_handler(
    State(state): State<Arc<Mutex<ApiServerState>>>,
    Path(collection_name): Path<String>,
    Query(params): Query<HashMap<String, String>>,
) -> impl IntoResponse {
    let mongodb_state = &state.lock().await.mongodb_state;
    
    // Extract filter from query parameters
    let filter_str = params.get("filter").cloned().unwrap_or_else(|| String::from("{}"));
    
    // Parse the JSON string into a Document
    let mut filter: Document = match serde_json::from_str(&filter_str) {
        Ok(f) => f,
        Err(e) => return error_response::<Vec<Document>>(
            StatusCode::BAD_REQUEST, 
            format!("Invalid filter JSON: {}", e)
        ),
    };
    
    // Add condition for empty archive history
    filter.insert("$or", vec![
        doc! { "archive_history": doc! { "$exists": false } },
        doc! { "archive_history": doc! { "$size": 0 } }
    ]);
    
    match get_database(mongodb_state).await {
        Ok(db) => {
            let collection = db.collection::<Document>(&collection_name);
            
            match collection.find(filter, None).await {
                Ok(cursor) => {
                    match process_cursor(cursor).await {
                        Ok(documents) => {
                            (StatusCode::OK, Json(ApiResponse {
                                success: true,
                                data: Some(documents),
                                error: None,
                            }))
                        },
                        Err(e) => error_response::<Vec<Document>>(StatusCode::INTERNAL_SERVER_ERROR, e),
                    }
                },
                Err(e) => error_response::<Vec<Document>>(StatusCode::INTERNAL_SERVER_ERROR, e.to_string()),
            }
        },
        Err((status, e)) => error_response::<Vec<Document>>(status, e),
    }
}

pub async fn find_empty_or_recovered_documents_handler(
    State(state): State<Arc<Mutex<ApiServerState>>>,
    Path(collection_name): Path<String>,
    Query(params): Query<HashMap<String, String>>,
) -> impl IntoResponse {
    let mongodb_state = &state.lock().await.mongodb_state;
    
    // Extract filter from query parameters
    let filter_str = params.get("filter").cloned().unwrap_or_else(|| String::from("{}"));
    
    // Parse the JSON string into a Document
    let mut filter: Document = match serde_json::from_str(&filter_str) {
        Ok(f) => f,
        Err(e) => return error_response::<Vec<Document>>(
            StatusCode::BAD_REQUEST, 
            format!("Invalid filter JSON: {}", e)
        ),
    };
    
    // Build the combined $or condition
    filter.insert("$or", vec![
        // Condition 1: Empty archive history (either doesn't exist or array is empty)
        doc! {
            "$or": [
                { "archive_history": { "$exists": false } },
                { "archive_history": { "$size": 0 } }
            ]
        },
        // Condition 2: Latest archive action is 'recover' and array is not empty
        doc! {
            "archive_history.0": { "$exists": true },
            "$expr": {
                "$eq": [
                    { "$arrayElemAt": ["$archive_history.action", -1] },
                    "recover"
                ]
            }
        }
    ]);
    
    // Execute the query with the combined filter
    match get_database(mongodb_state).await {
        Ok(db) => {
            let collection = db.collection::<Document>(&collection_name);
            
            match collection.find(filter, None).await {
                Ok(cursor) => {
                    match process_cursor(cursor).await {
                        Ok(documents) => {
                            (StatusCode::OK, Json(ApiResponse {
                                success: true,
                                data: Some(documents),
                                error: None,
                            }))
                        },
                        Err(e) => error_response::<Vec<Document>>(StatusCode::INTERNAL_SERVER_ERROR, e),
                    }
                },
                Err(e) => error_response::<Vec<Document>>(StatusCode::INTERNAL_SERVER_ERROR, e.to_string()),
            }
        },
        Err((status, e)) => error_response::<Vec<Document>>(status, e),
    }
}

pub async fn find_pinned_documents_handler(
    State(state): State<Arc<Mutex<ApiServerState>>>,
    Path(collection_name): Path<String>,
    Query(params): Query<HashMap<String, String>>,
    TypedHeader(auth): TypedHeader<Authorization<Bearer>>,
) -> impl IntoResponse {
    // Validate auth token and get user_id
    let user_id = match async {
        let state_guard = state.lock().await;
        let session_manager_mutex = &state_guard.session_manager;
        let session_manager = session_manager_mutex.lock().await;
        
        let token = auth.token();
        
        if session_manager.validate_session(token).await {
            // If session is valid, get the user ID
            match session_manager.get_user_id(token).await {
                Some(user_id) => Ok(user_id),
                None => Err("Session valid but user ID not found".to_string())
            }
        } else {
            Err("Invalid or expired session".to_string())
        }
    }.await {
        Ok(id) => id,
        Err(e) => return error_response::<Vec<Document>>(
            StatusCode::UNAUTHORIZED,
            format!("Authentication failed: {}", e)
        ),
    };
    
    let mongodb_state = &state.lock().await.mongodb_state;
    
    let filter_str = params.get("filter").cloned().unwrap_or_else(|| String::from("{}"));
    
    let mut filter: Document = match serde_json::from_str(&filter_str) {
        Ok(f) => f,
        Err(e) => return error_response::<Vec<Document>>(
            StatusCode::BAD_REQUEST, 
            format!("Invalid filter JSON: {}", e)
        ),
    };
    
    // Filter for documents pinned by this user
    filter.insert("pinned_by", user_id);
    
    match get_database(mongodb_state).await {
        Ok(db) => {
            // Check if the collection supports pinning
            let schema = match get_collection_schema_internal(&db, &collection_name).await {
                Ok(s) => s,
                Err(e) => return error_response::<Vec<Document>>(
                    StatusCode::INTERNAL_SERVER_ERROR, 
                    e
                ),
            };

            if !schema_has_pinned_property(&schema) {
                return error_response::<Vec<Document>>(
                    StatusCode::BAD_REQUEST,
                    "This collection does not support pinning.".into(),
                );
            }
            
            let collection = db.collection::<Document>(&collection_name);
            
            match collection.find(filter, None).await {
                Ok(cursor) => {
                    match process_cursor(cursor).await {
                        Ok(documents) => {
                            (StatusCode::OK, Json(ApiResponse {
                                success: true,
                                data: Some(documents),
                                error: None,
                            }))
                        },
                        Err(e) => error_response::<Vec<Document>>(StatusCode::INTERNAL_SERVER_ERROR, e),
                    }
                },
                Err(e) => error_response::<Vec<Document>>(StatusCode::INTERNAL_SERVER_ERROR, e.to_string()),
            }
        },
        Err((status, e)) => error_response::<Vec<Document>>(status, e),
    }
}

pub async fn insert_document_handler(
    State(state): State<Arc<Mutex<ApiServerState>>>,
    Path(collection_name): Path<String>,
    Json(document): Json<serde_json::Value>,
) -> impl IntoResponse {
    let mongodb_state = &state.lock().await.mongodb_state;
    
    match get_database(mongodb_state).await {
        Ok(db) => {
            // Convert JSON to BSON document
            let doc_result = mongodb::bson::to_document(&document);
            match doc_result {
                Ok(mut doc) => {
                    // Remove any client-provided timestamp fields
                    doc.remove("created_at");
                    doc.remove("updated_at");
                    
                    // For attendance collection, also handle time_in_date
                    if collection_name == "attendance" {
                        doc.remove("time_in_date");
                    }
                    
                    // Add server-managed timestamp fields
                    let current_time = mongodb::bson::DateTime::now();
                    doc.insert("created_at", current_time.clone());
                    
                    // For attendance collection, also set time_in_date
                    if collection_name == "attendance" {
                        doc.insert("time_in_date", current_time);
                    }
                    
                    // Process fields according to schema types (dates, integers, etc.)
                    if let Err(e) = process_document_fields(&db, &collection_name, &mut doc).await {
                        return error_response::<InsertResponse>(StatusCode::BAD_REQUEST, e);
                    }
                    
                    // Insert the document
                    let collection = db.collection::<Document>(&collection_name);
                    match collection.insert_one(doc, None).await {
                        Ok(result) => {
                            match result.inserted_id.as_object_id() {
                                Some(id) => {
                                    (StatusCode::CREATED, Json(ApiResponse {
                                        success: true,
                                        data: Some(InsertResponse { id: id.to_hex() }),
                                        error: None,
                                    }))
                                },
                                None => error_response::<InsertResponse>(
                                    StatusCode::INTERNAL_SERVER_ERROR, 
                                    "Failed to get inserted document ID".into()
                                ),
                            }
                        },
                        Err(e) => error_response::<InsertResponse>(StatusCode::INTERNAL_SERVER_ERROR, e.to_string()),
                    }
                },
                Err(e) => error_response::<InsertResponse>(
                    StatusCode::BAD_REQUEST, 
                    format!("Failed to convert document to BSON: {}", e)
                ),
            }
        },
        Err((status, e)) => error_response::<InsertResponse>(status, e),
    }
}

pub async fn update_document_handler(
    State(state): State<Arc<Mutex<ApiServerState>>>,
    Path((collection_name, id)): Path<(String, String)>,
    Json(update): Json<Document>,
) -> impl IntoResponse {
    let mongodb_state = &state.lock().await.mongodb_state;
    
    match get_database(mongodb_state).await {
        Ok(db) => {
            // Parse ObjectId
            match ObjectId::parse_str(&id) {
                Ok(object_id) => {
                    let collection = db.collection::<Document>(&collection_name);
                    let filter = doc! { "_id": object_id };
                    
                    // Process fields in the update document according to the schema
                    let mut update_doc = update.clone();
                    
                    // Remove any attempts to modify timestamp fields
                    update_doc.remove("created_at");
                    
                    // Check if the update contains only row_height
                    // Count keys in update_doc and check if row_height is the only one
                    let keys: Vec<_> = update_doc.keys().collect();
                    let is_row_height_only = keys.len() == 1 && keys[0] == "row_height";
                    
                    // Only update timestamp if other fields are being modified
                    if !is_row_height_only {
                        let current_time = mongodb::bson::DateTime::now();
                        update_doc.insert("updated_at", current_time);
                    }
                    
                    if let Err(e) = process_document_fields(&db, &collection_name, &mut update_doc).await {
                        return error_response::<UpdateResponse>(StatusCode::BAD_REQUEST, e);
                    }
                    
                    let update_bson = doc! { "$set": update_doc };
                    
                    // Use FindOneAndUpdateOptions to return the updated document
                    let options = FindOneAndUpdateOptions::builder()
                        .return_document(ReturnDocument::After)
                        .build();

                    match collection.find_one_and_update(filter, update_bson, options).await {
                        Ok(Some(mut updated_doc)) => {
                            // Format the date fields for proper JSON serialization
                            format_date_fields(&mut updated_doc);
                            
                            (StatusCode::OK, Json(ApiResponse {
                                success: true,
                                data: Some(UpdateResponse {
                                    success: true,
                                    modified_count: 1,
                                    document: Some(updated_doc),
                                }),
                                error: None,
                            }))
                        },
                        Ok(None) => error_response::<UpdateResponse>(
                            StatusCode::NOT_FOUND, 
                            "Document not found".into()
                        ),
                        Err(e) => error_response::<UpdateResponse>(
                            StatusCode::INTERNAL_SERVER_ERROR, 
                            e.to_string()
                        ),
                    }
                },
                Err(e) => error_response::<UpdateResponse>(
                    StatusCode::BAD_REQUEST, 
                    format!("Invalid ObjectId: {}", e)
                ),
            }
        },
        Err((status, e)) => error_response::<UpdateResponse>(status, e),
    }
}

pub async fn delete_document_handler(
    State(state): State<Arc<Mutex<ApiServerState>>>,
    Path((collection_name, id)): Path<(String, String)>,
) -> impl IntoResponse {
    let mongodb_state = &state.lock().await.mongodb_state;
    
    match get_database(mongodb_state).await {
        Ok(db) => {
            // Parse ObjectId
            match ObjectId::parse_str(&id) {
                Ok(object_id) => {
                    let collection = db.collection::<Document>(&collection_name);
                    let filter = doc! { "_id": object_id };
                    
                    match collection.delete_one(filter, None).await {
                        Ok(result) => {
                            (StatusCode::OK, Json(ApiResponse {
                                success: true,
                                data: Some(DeleteResponse {
                                    success: true,
                                    deleted_count: result.deleted_count,
                                }),
                                error: None,
                            }))
                        },
                        Err(e) => error_response::<DeleteResponse>(StatusCode::INTERNAL_SERVER_ERROR, e.to_string()),
                    }
                },
                Err(e) => error_response::<DeleteResponse>(
                    StatusCode::BAD_REQUEST, 
                    format!("Invalid ObjectId: {}", e)
                ),
            }
        },
        Err((status, e)) => error_response::<DeleteResponse>(status, e),
    }
}

pub async fn batch_delete_documents_handler(
    State(state): State<Arc<Mutex<ApiServerState>>>,
    Path(collection_name): Path<String>,
    Json(payload): Json<HashMap<String, Vec<String>>>,
) -> impl IntoResponse {
    let mongodb_state = &state.lock().await.mongodb_state;
    
    let ids = match payload.get("ids") {
        Some(ids) => ids,
        None => return error_response::<DeleteResponse>(
            StatusCode::BAD_REQUEST, 
            "Missing 'ids' in payload".into()
        ),
    };

    let object_ids: Result<Vec<ObjectId>, _> = ids.iter()
        .map(|id| ObjectId::parse_str(id))
        .collect();

    let object_ids = match object_ids {
        Ok(ids) => ids,
        Err(e) => return error_response::<DeleteResponse>(
            StatusCode::BAD_REQUEST, 
            format!("Invalid ObjectId: {}", e)
        ),
    };

    match get_database(mongodb_state).await {
        Ok(db) => {
            let collection = db.collection::<Document>(&collection_name);
            let filter = doc! { "_id": { "$in": object_ids } };
            
            match collection.delete_many(filter, None).await {
                Ok(result) => {
                    (StatusCode::OK, Json(ApiResponse {
                        success: true,
                        data: Some(DeleteResponse {
                            success: true,
                            deleted_count: result.deleted_count,
                        }),
                        error: None,
                    }))
                },
                Err(e) => error_response::<DeleteResponse>(
                    StatusCode::INTERNAL_SERVER_ERROR, 
                    e.to_string()
                ),
            }
        },
        Err((status, e)) => error_response::<DeleteResponse>(status, e),
    }
}

// archive handlers

pub async fn archive_document_handler(
    State(state): State<Arc<Mutex<ApiServerState>>>,
    Path((collection_name, id)): Path<(String, String)>,
    TypedHeader(auth): TypedHeader<Authorization<Bearer>>,
) -> impl IntoResponse {
    let token = auth.token();
    let state = state.lock().await;
    let session_manager = &state.session_manager;
    
    // Validate session
    let valid = session_manager.lock().await.validate_session(token).await;
    if !valid {
        return error_response::<()>(StatusCode::UNAUTHORIZED, "Invalid session".into());
    }

    // Get user ID from session
    let user_id = match session_manager.lock().await.get_user_id(token).await {
        Some(id) => id,
        None => return error_response::<()>(StatusCode::UNAUTHORIZED, "Session expired".into()),
    };

    // Convert to ObjectId
    let user_oid = match ObjectId::parse_str(&user_id) {
        Ok(oid) => oid,
        Err(_) => return error_response::<()>(StatusCode::INTERNAL_SERVER_ERROR, "Invalid user ID format".into()),
    };

    // Process the archive operation
    match get_database(&state.mongodb_state).await {
        Ok(db) => {
            let collection = db.collection::<Document>(&collection_name);
            let doc_id = match ObjectId::parse_str(&id) {
                Ok(oid) => oid,
                Err(e) => return error_response::<()>(StatusCode::BAD_REQUEST, format!("Invalid document ID: {}", e)),
            };

            // Create timestamp
            let now = mongodb::bson::DateTime::now();

            // Try to update only if not already archived
            let filter = doc! {
                "_id": doc_id,
                "is_archive": { "$ne": true }
            };

            let update = doc! {
                "$set": { "is_archive": true },
                "$push": {
                    "archive_history": {
                        "action": "archive",
                        "user_id": user_oid,
                        "timestamp": now
                    }
                }
            };

            match collection.update_one(filter, update, None).await {
                Ok(result) => {
                    if result.matched_count == 0 {
                        // Check if document exists
                        match collection.count_documents(doc! { "_id": doc_id }, None).await {
                            Ok(count) if count > 0 => {
                                // Document exists but already archived
                                (StatusCode::OK, Json(ApiResponse {
                                    success: true,
                                    data: Some(()),
                                    error: None,
                                }))
                            },
                            _ => error_response::<()>(StatusCode::NOT_FOUND, "Document not found".into()),
                        }
                    } else {
                        (StatusCode::OK, Json(ApiResponse {
                            success: true,
                            data: Some(()),
                            error: None,
                        }))
                    }
                },
                Err(e) => error_response::<()>(StatusCode::INTERNAL_SERVER_ERROR, e.to_string()),
            }
        },
        Err((status, e)) => error_response::<()>(status, e),
    }
}

pub async fn batch_archive_documents_handler(
    State(state): State<Arc<Mutex<ApiServerState>>>,
    Path(collection_name): Path<String>,
    TypedHeader(auth): TypedHeader<Authorization<Bearer>>,
    Json(payload): Json<HashMap<String, Vec<String>>>,
) -> impl IntoResponse {
    let token = auth.token();
    let state = state.lock().await;
    let session_manager = &state.session_manager;
    
    // Authentication check
    let valid = session_manager.lock().await.validate_session(token).await;
    if !valid {
        return error_response::<serde_json::Value>(
            StatusCode::UNAUTHORIZED, 
            "Invalid session".into()
        );
    }

    // Get user ID from session
    let user_id = match session_manager.lock().await.get_user_id(token).await {
        Some(id) => id,
        None => return error_response::<serde_json::Value>(
            StatusCode::UNAUTHORIZED, 
            "Session expired".into()
        ),
    };

    // Convert to ObjectId
    let user_oid = match ObjectId::parse_str(&user_id) {
        Ok(oid) => oid,
        Err(_) => return error_response::<serde_json::Value>(
            StatusCode::INTERNAL_SERVER_ERROR, 
            "Invalid user ID format".into()
        ),
    };

    let ids = match payload.get("ids") {
        Some(ids) => ids,
        None => return error_response::<serde_json::Value>(
            StatusCode::BAD_REQUEST, 
            "Missing 'ids' in payload".into()
        ),
    };

    // Convert string IDs to ObjectIds
    let object_ids: Result<Vec<ObjectId>, _> = ids.iter()
        .map(|id| ObjectId::parse_str(id))
        .collect();

    let object_ids = match object_ids {
        Ok(ids) => ids,
        Err(e) => return error_response::<serde_json::Value>(
            StatusCode::BAD_REQUEST, 
            format!("Invalid ObjectId: {}", e)
        ),
    };

    match get_database(&state.mongodb_state).await {
        Ok(db) => {
            let collection = db.collection::<Document>(&collection_name);
            let now = mongodb::bson::DateTime::now();

            // First check if all documents are already archived
            let count_total = match collection.count_documents(
                doc! { "_id": { "$in": &object_ids } },
                None
            ).await {
                Ok(count) => count,
                Err(e) => return error_response::<serde_json::Value>(
                    StatusCode::INTERNAL_SERVER_ERROR, 
                    e.to_string()
                ),
            };

            let count_already_archived = match collection.count_documents(
                doc! { 
                    "_id": { "$in": &object_ids },
                    "is_archive": true 
                },
                None
            ).await {
                Ok(count) => count,
                Err(e) => return error_response::<serde_json::Value>(
                    StatusCode::INTERNAL_SERVER_ERROR, 
                    e.to_string()
                ),
            };

            // If all documents are already archived
            if count_already_archived == count_total {
                return (StatusCode::OK, Json(ApiResponse {
                    success: true,
                    data: Some(json!({
                        "message": "All selected documents are already archived",
                        "archived_count": 0
                    })),
                    error: None,
                }));
            }

            // Update only non-archived documents
            let filter = doc! {
                "_id": { "$in": &object_ids },
                "is_archive": { "$ne": true }
            };

            let update = doc! {
                "$set": { "is_archive": true },
                "$push": {
                    "archive_history": {
                        "action": "archive",
                        "user_id": user_oid,
                        "timestamp": now
                    }
                }
            };

            match collection.update_many(filter, update, None).await {
                Ok(result) => {
                    (StatusCode::OK, Json(ApiResponse {
                        success: true,
                        data: Some(json!({
                            "message": format!("Successfully archived {} documents", result.modified_count),
                            "archived_count": result.modified_count
                        })),
                        error: None,
                    }))
                },
                Err(e) => error_response::<serde_json::Value>(
                    StatusCode::INTERNAL_SERVER_ERROR, 
                    e.to_string()
                ),
            }
        },
        Err((status, e)) => error_response::<serde_json::Value>(status, e),
    }
}

// recovery handlers

pub async fn recover_document_handler(
    State(state): State<Arc<Mutex<ApiServerState>>>,
    Path((collection_name, id)): Path<(String, String)>,
    TypedHeader(auth): TypedHeader<Authorization<Bearer>>,
) -> impl IntoResponse {
    let token = auth.token();
    let state = state.lock().await;
    let session_manager = &state.session_manager;
    
    // Validate session
    let valid = session_manager.lock().await.validate_session(token).await;
    if !valid {
        return error_response::<()>(StatusCode::UNAUTHORIZED, "Invalid session".into());
    }

    // Get user ID from session
    let user_id = match session_manager.lock().await.get_user_id(token).await {
        Some(id) => id,
        None => return error_response::<()>(StatusCode::UNAUTHORIZED, "Session expired".into()),
    };

    // Convert to ObjectId
    let user_oid = match ObjectId::parse_str(&user_id) {
        Ok(oid) => oid,
        Err(_) => return error_response::<()>(StatusCode::INTERNAL_SERVER_ERROR, "Invalid user ID format".into()),
    };

    match get_database(&state.mongodb_state).await {
        Ok(db) => {
            let collection = db.collection::<Document>(&collection_name);
            let doc_id = match ObjectId::parse_str(&id) {
                Ok(oid) => oid,
                Err(e) => return error_response::<()>(StatusCode::BAD_REQUEST, format!("Invalid document ID: {}", e)),
            };

            let now = mongodb::bson::DateTime::now();

            // Try to update only if archived
            let filter = doc! {
                "_id": doc_id,
                "is_archive": true
            };

            let update = doc! {
                "$set": { "is_archive": false },
                "$push": {
                    "archive_history": {
                        "action": "recover",
                        "user_id": user_oid,
                        "timestamp": now
                    }
                }
            };

            match collection.update_one(filter, update, None).await {
                Ok(result) => {
                    if result.matched_count == 0 {
                        match collection.count_documents(doc! { "_id": doc_id }, None).await {
                            Ok(count) if count > 0 => (StatusCode::OK, Json(ApiResponse {
                                success: true,
                                data: Some(()),
                                error: None,
                            })),
                            _ => error_response::<()>(StatusCode::NOT_FOUND, "Document not found".into()),
                        }
                    } else {
                        (StatusCode::OK, Json(ApiResponse {
                            success: true,
                            data: Some(()),
                            error: None,
                        }))
                    }
                },
                Err(e) => error_response::<()>(StatusCode::INTERNAL_SERVER_ERROR, e.to_string()),
            }
        },
        Err((status, e)) => error_response::<()>(status, e),
    }
}

pub async fn batch_recover_documents_handler(
    State(state): State<Arc<Mutex<ApiServerState>>>,
    Path(collection_name): Path<String>,
    TypedHeader(auth): TypedHeader<Authorization<Bearer>>,
    Json(payload): Json<HashMap<String, Vec<String>>>,
) -> impl IntoResponse {
    let token = auth.token();
    let state = state.lock().await;
    let session_manager = &state.session_manager;
    
    let valid = session_manager.lock().await.validate_session(token).await;
    if !valid {
        return error_response::<serde_json::Value>(
            StatusCode::UNAUTHORIZED, 
            "Invalid session".into()
        );
    }

    let user_id = match session_manager.lock().await.get_user_id(token).await {
        Some(id) => id,
        None => return error_response::<serde_json::Value>(
            StatusCode::UNAUTHORIZED, 
            "Session expired".into()
        ),
    };

    let user_oid = match ObjectId::parse_str(&user_id) {
        Ok(oid) => oid,
        Err(_) => return error_response::<serde_json::Value>(
            StatusCode::INTERNAL_SERVER_ERROR, 
            "Invalid user ID format".into()
        ),
    };

    let ids = match payload.get("ids") {
        Some(ids) => ids,
        None => return error_response::<serde_json::Value>(
            StatusCode::BAD_REQUEST, 
            "Missing 'ids' in payload".into()
        ),
    };

    let object_ids: Result<Vec<ObjectId>, _> = ids.iter()
        .map(|id| ObjectId::parse_str(id))
        .collect();

    let object_ids = match object_ids {
        Ok(ids) => ids,
        Err(e) => return error_response::<serde_json::Value>(
            StatusCode::BAD_REQUEST, 
            format!("Invalid ObjectId: {}", e)
        ),
    };

    match get_database(&state.mongodb_state).await {
        Ok(db) => {
            let collection = db.collection::<Document>(&collection_name);
            let now = mongodb::bson::DateTime::now();

            let count_archived = match collection.count_documents(
                doc! { 
                    "_id": { "$in": &object_ids },
                    "is_archive": true 
                },
                None
            ).await {
                Ok(count) => count,
                Err(e) => return error_response::<serde_json::Value>(
                    StatusCode::INTERNAL_SERVER_ERROR, 
                    e.to_string()
                ),
            };

            if count_archived == 0 {
                return (StatusCode::OK, Json(ApiResponse {
                    success: true,
                    data: Some(json!({
                        "message": "No archived documents found to recover",
                        "recovered_count": 0
                    })),
                    error: None,
                }));
            }

            let filter = doc! {
                "_id": { "$in": &object_ids },
                "is_archive": true
            };

            let update = doc! {
                "$set": { "is_archive": false },
                "$push": {
                    "archive_history": {
                        "action": "recover",
                        "user_id": user_oid,
                        "timestamp": now
                    }
                }
            };

            match collection.update_many(filter, update, None).await {
                Ok(result) => {
                    (StatusCode::OK, Json(ApiResponse {
                        success: true,
                        data: Some(json!({
                            "message": format!("Successfully recovered {} documents", result.modified_count),
                            "recovered_count": result.modified_count
                        })),
                        error: None,
                    }))
                },
                Err(e) => error_response::<serde_json::Value>(
                    StatusCode::INTERNAL_SERVER_ERROR, 
                    e.to_string()
                ),
            }
        },
        Err((status, e)) => error_response::<serde_json::Value>(status, e),
    }
}

// pin and unpin handlers
pub async fn pin_document_handler(
    State(state): State<Arc<Mutex<ApiServerState>>>,
    Path((collection_name, id)): Path<(String, String)>,
    TypedHeader(auth): TypedHeader<Authorization<Bearer>>,
) -> impl IntoResponse {
    tracing::debug!(
        "pin_document_handler called: collection={}, document_id={}", 
        collection_name, id
    );
    
    let token = auth.token();
    let state = state.lock().await;
    let session_manager = &state.session_manager;
    
    let valid = session_manager.lock().await.validate_session(token).await;
    if !valid {
        tracing::warn!("pin_document_handler: Invalid session token");
        return error_response::<Document>(StatusCode::UNAUTHORIZED, "Invalid session".into());
    }

    let user_id = match session_manager.lock().await.get_user_id(token).await {
        Some(id) => id,
        None => {
            tracing::warn!("pin_document_handler: Session expired");
            return error_response::<Document>(StatusCode::UNAUTHORIZED, "Session expired".into());
        }
    };

    // temporary commented, TODO: check this part if truly not needed
    // let user_oid = match ObjectId::parse_str(&user_id) {
    //     Ok(oid) => oid,
    //     Err(e) => {
    //         tracing::error!("pin_document_handler: Invalid user ID format: {}", e);
    //         return error_response::<Document>(StatusCode::INTERNAL_SERVER_ERROR, "Invalid user ID format".into());
    //     }
    // };

    match get_database(&state.mongodb_state).await {
        Ok(db) => {
            let schema = match get_collection_schema_internal(&db, &collection_name).await {
                Ok(s) => s,
                Err(e) => {
                    tracing::error!("pin_document_handler: Failed to get schema: {}", e);
                    return error_response::<Document>(StatusCode::INTERNAL_SERVER_ERROR, e);
                }
            };

            if !schema_has_pinned_property(&schema) {
                tracing::warn!("pin_document_handler: Collection doesn't support pinning");
                return error_response::<Document>(
                    StatusCode::BAD_REQUEST,
                    "Collection does not support pinning".into(),
                );
            }

            let collection = db.collection::<Document>(&collection_name);
            let doc_id = match ObjectId::parse_str(&id) {
                Ok(oid) => oid,
                Err(e) => {
                    tracing::warn!("pin_document_handler: Invalid document ID: {}", e);
                    return error_response::<Document>(StatusCode::BAD_REQUEST, format!("Invalid document ID: {}", e));
                }
            };

            let now = mongodb::bson::DateTime::now();
            let filter = doc! {
                "_id": doc_id,
                "pinned_by": { "$ne": &user_id }  // Use a reference here
            };
            let update = doc! {
                "$addToSet": { "pinned_by": &user_id },
                "$push": {
                    "pinned_history": {
                        "action": "pin",
                        "user_id": &user_id, // Store the user_id string
                        "timestamp": now
                    }
                },
                "$set": { "updated_at": now }
            };            
            
            let options = FindOneAndUpdateOptions::builder()
                .return_document(ReturnDocument::After)
                .build();

                match collection.find_one_and_update(filter, update, options).await {
                    Ok(Some(mut updated_doc)) => {
                        format_date_fields(&mut updated_doc);
                        tracing::info!("Successfully pinned document {}", id);
                        let response = Json(ApiResponse {
                            success: true,
                            data: Some(updated_doc),
                            error: None,
                        });
                        tracing::info!("Response: {:?}", response); // Log the success response
                        (StatusCode::OK, response)
                    },
                Ok(None) => {
                    match collection.find_one(doc! { "_id": doc_id }, None).await {
                        Ok(Some(mut existing_doc)) => {
                            format_date_fields(&mut existing_doc);
                            (StatusCode::OK, Json(ApiResponse {
                                success: true,
                                data: Some(existing_doc),
                                error: None,
                            }))
                        },
                        Ok(None) => {
                            tracing::warn!("Document not found: {}", id);
                            error_response::<Document>(StatusCode::NOT_FOUND, "Document not found".into())
                        },
                        Err(e) => {
                            tracing::error!("Database error: {}", e);
                            error_response::<Document>(StatusCode::INTERNAL_SERVER_ERROR, e.to_string())
                        }
                    }
                },
                Err(e) => {
                    tracing::error!("Update error: {}", e);
                    error_response::<Document>(StatusCode::INTERNAL_SERVER_ERROR, e.to_string())
                }
            }
        },
        Err((status, e)) => {
            tracing::error!("Database connection error: {}", e);
            error_response::<Document>(status, e)
        },
    }
}

pub async fn unpin_document_handler(
    State(state): State<Arc<Mutex<ApiServerState>>>,
    Path((collection_name, id)): Path<(String, String)>,
    TypedHeader(auth): TypedHeader<Authorization<Bearer>>,
) -> impl IntoResponse {
    tracing::debug!(
        "unpin_document_handler called: collection={}, document_id={}", 
        collection_name, id
    );
    
    let token = auth.token();
    let state = state.lock().await;
    let session_manager = &state.session_manager;
    
    let valid = session_manager.lock().await.validate_session(token).await;
    if !valid {
        tracing::warn!("unpin_document_handler: Invalid session token");
        return error_response::<Document>(StatusCode::UNAUTHORIZED, "Invalid session".into());
    }

    let user_id = match session_manager.lock().await.get_user_id(token).await {
        Some(id) => id,
        None => {
            tracing::warn!("unpin_document_handler: Session expired");
            return error_response::<Document>(StatusCode::UNAUTHORIZED, "Session expired".into());
        }
    };

    // temporary commented, TODO: check this part if truly not needed
    // let user_oid = match ObjectId::parse_str(&user_id) {
    //     Ok(oid) => oid,
    //     Err(e) => {
    //         tracing::error!("unpin_document_handler: Invalid user ID format: {}", e);
    //         return error_response::<Document>(StatusCode::INTERNAL_SERVER_ERROR, "Invalid user ID format".into());
    //     }
    // };

    match get_database(&state.mongodb_state).await {
        Ok(db) => {
            let schema = match get_collection_schema_internal(&db, &collection_name).await {
                Ok(s) => s,
                Err(e) => {
                    tracing::error!("unpin_document_handler: Failed to get schema: {}", e);
                    return error_response::<Document>(StatusCode::INTERNAL_SERVER_ERROR, e);
                }
            };

            if !schema_has_pinned_property(&schema) {
                tracing::warn!("unpin_document_handler: Collection doesn't support pinning");
                return error_response::<Document>(
                    StatusCode::BAD_REQUEST,
                    "Collection does not support pinning".into(),
                );
            }

            let collection = db.collection::<Document>(&collection_name);
            let doc_id = match ObjectId::parse_str(&id) {
                Ok(oid) => oid,
                Err(e) => {
                    tracing::warn!("unpin_document_handler: Invalid document ID: {}", e);
                    return error_response::<Document>(StatusCode::BAD_REQUEST, format!("Invalid document ID: {}", e));
                }
            };

            let now = mongodb::bson::DateTime::now();
            let filter = doc! {
                "_id": doc_id,
                "pinned_by": &user_id  // Use a reference here
            };
            let update = doc! {
                "$pull": { "pinned_by": &user_id },
                "$push": {
                    "pinned_history": {
                        "action": "unpin",
                        "user_id": &user_id, // Store the user_id string
                        "timestamp": now
                    }
                },
                "$set": { "updated_at": now }
            };

            let options = FindOneAndUpdateOptions::builder()
                .return_document(ReturnDocument::After)
                .build();

            match collection.find_one_and_update(filter, update, options).await {
                Ok(Some(mut updated_doc)) => {
                    format_date_fields(&mut updated_doc);
                    tracing::info!("Successfully unpinned document {}", id);
                    let response = Json(ApiResponse {
                        success: true,
                        data: Some(updated_doc),
                        error: None,
                    });
                    tracing::info!("Response: {:?}", response); // Log the success response
                    (StatusCode::OK, response)
                },
                Ok(None) => {
                    match collection.find_one(doc! { "_id": doc_id }, None).await {
                        Ok(Some(mut existing_doc)) => {
                            format_date_fields(&mut existing_doc);
                            (StatusCode::OK, Json(ApiResponse {
                                success: true,
                                data: Some(existing_doc),
                                error: None,
                            }))
                        },
                        Ok(None) => {
                            tracing::warn!("Document not found: {}", id);
                            error_response::<Document>(StatusCode::NOT_FOUND, "Document not found".into())
                        },
                        Err(e) => {
                            tracing::error!("Database error: {}", e);
                            error_response::<Document>(StatusCode::INTERNAL_SERVER_ERROR, e.to_string())
                        }
                    }
                },
                Err(e) => {
                    tracing::error!("Update error: {}", e);
                    error_response::<Document>(StatusCode::INTERNAL_SERVER_ERROR, e.to_string())
                }
            }
        },
        Err((status, e)) => {
            tracing::error!("Database connection error: {}", e);
            error_response::<Document>(status, e)
        },
    }
}

// Helper function to check if the schema includes the 'pinned_by' property
fn schema_has_pinned_property(schema: &Document) -> bool {
    if let Ok(properties) = schema.get_document("properties") {
        let has = properties.contains_key("pinned_by");
        tracing::debug!("Schema has pinned_by: {}", has);
        has
    } else {
        tracing::error!("Schema properties not found");
        false
    }
}

// Helper functions for document handlers
pub async fn process_cursor(
    mut cursor: Cursor<Document>
) -> Result<Vec<Document>, String> {
    let mut documents = Vec::new();
    while let Some(document_result) = cursor.next().await {
        match document_result {
            Ok(mut doc) => {
                format_date_fields(&mut doc);
                documents.push(doc);
            },
            Err(e) => return Err(format!("Error retrieving document: {}", e)),
        }
    }
    
    Ok(documents)
}

pub fn format_date_fields(doc: &mut Document) {
    // Similar to your existing implementation
    let keys: Vec<String> = doc.keys().cloned().collect();
    
    for key in keys {
        if let Some(mongodb::bson::Bson::DateTime(date_time)) = doc.get(&key) {
            let chrono_date = chrono::DateTime::from_timestamp_millis(date_time.timestamp_millis())
                .unwrap_or_else(|| chrono::DateTime::from_timestamp(0, 0).unwrap());
            
            let formatted_date = chrono_date.format("%Y-%m-%d %H:%M:%S").to_string();
            doc.insert(key, mongodb::bson::Bson::String(formatted_date));
        }
    }
}
// src/api_server/services/schema_service.rs

use mongodb::{bson::{doc, Document}, Database};
use tracing::error;

// Get collection schema - extract common functionality for reuse
pub async fn get_collection_schema_internal(db: &Database, collection_name: &str) -> Result<Document, String> {
    let command = doc! {
        "listCollections": 1,
        "filter": { "name": collection_name }
    };
    
    let response = db.run_command(command, None)
        .await
        .map_err(|e| format!("Failed to get collection info: {}", e))?;
    
    let cursor = response.get_document("cursor")
        .map_err(|e| format!("Invalid response format: {}", e))?;
    
    let batches = cursor.get_array("firstBatch")
        .map_err(|_| "No collections found".to_string())?;
    
    if batches.is_empty() {
        return Err("Collection not found".into());
    }
    
    let coll_info = batches[0].as_document()
        .ok_or_else(|| "Invalid collection info".to_string())?;
    
    let options = coll_info.get_document("options")
        .map_err(|_| "No options found".to_string())?;
    
    let validator = options.get_document("validator")
        .map_err(|_| "No validator found".to_string())?;
    
    let json_schema = validator.get_document("$jsonSchema")
        .map_err(|_| "No JSON schema found".to_string())?;
    
    Ok(json_schema.clone())
}

// Get collection schema with UI metadata
pub async fn get_collection_schema_with_ui(
    db: &Database, 
    collection_name: &str
) -> Result<Document, String> {
    let schema = get_collection_schema_internal(db, collection_name).await?;
    
    // Fetch UI metadata from ui_metadata collection
    let ui_metadata_collection = db.collection::<Document>("ui_metadata");
    let filter = doc! {
        "collection": collection_name,
        "user_id": { "$exists": false } // Global settings
    };
    
    // Try to get UI metadata
    match ui_metadata_collection.find_one(filter, None).await {
        Ok(ui_metadata) => {
            let mut merged_schema = schema.clone();
            if let Some(ui_metadata_doc) = ui_metadata {
                if let Ok(ui) = ui_metadata_doc.get_document("ui") {
                    merged_schema.insert("ui", ui.clone());
                }
            }
            Ok(merged_schema)
        },
        Err(e) => {
            error!("Failed to fetch UI metadata: {}", e);
            // If we can't get UI metadata, just return the base schema
            Ok(schema)
        }
    }
}

// Update UI metadata for a collection
pub async fn update_ui_metadata(
    db: &Database,
    collection_name: &str,
    column_widths: &serde_json::Value
) -> Result<(), String> {
    // Convert column widths to BSON
    let bson_column_widths = mongodb::bson::to_bson(column_widths)
        .map_err(|e| format!("Failed to convert column widths to BSON: {}", e))?;
    
    let update_doc = doc! {
        "$set": {
            "ui.columnWidths": bson_column_widths,
            "updated_at": mongodb::bson::DateTime::now()
        }
    };

    let filter = doc! {
        "collection": collection_name,
        "user_id": { "$exists": false } // Global settings
    };

    let options = mongodb::options::UpdateOptions::builder()
        .upsert(true)
        .build();

    db.collection::<Document>("ui_metadata")
        .update_one(filter, update_doc, options)
        .await
        .map_err(|e| format!("Failed to update UI metadata: {}", e))?;
    
    Ok(())
}

// src/api_server/services/database_service.rs

use axum::http::StatusCode;
use mongodb::{bson::{Document, Bson}, Database};
use std::{sync::Arc, time::SystemTime};
use tokio::sync::Mutex;

// Get database connection
pub async fn get_database(mongodb_state: &Arc<Mutex<MongoDbState>>) -> Result<Database, (StatusCode, String)> {
    let state = mongodb_state.lock().await;
    match state.get_database().await {
        Ok(db) => Ok(db),
        Err(e) => Err((StatusCode::INTERNAL_SERVER_ERROR, e)),
    }
}

// Process all types of fields according to schema
pub async fn process_document_fields(
    db: &Database, 
    collection_name: &str, 
    doc: &mut Document
) -> Result<(), String> {
    // Get collection schema
    let schema = crate::api_server::services::schema_service::get_collection_schema_internal(db, collection_name).await?;
    
    if let Some(properties) = schema.get("properties").and_then(|p| p.as_document()) {
        for (field, spec) in properties.iter() {
            // Skip if field doesn't exist in document
            if !doc.contains_key(field) {
                continue;
            }
            
            if let Some(spec_doc) = spec.as_document() {
                if let Some(bson_type) = spec_doc.get("bsonType") {
                    let bson_type_str = bson_type.as_str().unwrap_or("");
                    
                    match bson_type_str {
                        // Handle date fields
                        "date" => {
                            process_date_field(doc, field)?;
                        },
                        // Handle integer fields
                        "int" => {
                            process_int_field(doc, field)?;
                        },
                        // Handle double/decimal fields
                        "double" => {
                            process_double_field(doc, field)?;
                        },
                        // Add other types as needed
                        _ => {}
                    }
                }
            }
        }
    }
    
    Ok(())
}

// Process date fields
pub fn process_date_field(doc: &mut Document, field: &str) -> Result<(), String> {
    if let Some(Bson::String(date_str)) = doc.get(field) {
        // Try to parse the date using different formats
        let datetime = if let Ok(dt) = chrono::DateTime::parse_from_rfc3339(date_str) {
            dt
        } else {
            // Try with extended format
            let extended_date_str = format!("{}:00Z", date_str);
            chrono::DateTime::parse_from_rfc3339(&extended_date_str)
                .map_err(|e| format!("Failed to parse date field '{}': {} - Error: {}", field, date_str, e))?
        };
        
        // Convert to SystemTime then to bson::DateTime
        let system_time: SystemTime = datetime.into();
        let mongo_date = mongodb::bson::DateTime::from_system_time(system_time);
        doc.insert(field, mongo_date);
    }
    
    Ok(())
}

// Process integer fields
pub fn process_int_field(doc: &mut Document, field: &str) -> Result<(), String> {
    match doc.get(field) {
        Some(Bson::String(int_str)) => {
            // Convert string to integer
            let int_value = int_str.parse::<i32>()
                .map_err(|e| format!("Failed to parse integer field '{}': {} - Error: {}", field, int_str, e))?;
            doc.insert(field, Bson::Int32(int_value));
        },
        Some(Bson::Double(double_val)) => {
            // Convert double to integer
            let int_value = *double_val as i32;
            doc.insert(field, Bson::Int32(int_value));
        },
        _ => {}
    }
    
    Ok(())
}

// Process double/decimal fields
pub fn process_double_field(doc: &mut Document, field: &str) -> Result<(), String> {
    match doc.get(field) {
        Some(Bson::String(double_str)) => {
            // Convert string to double
            let double_value = double_str.parse::<f64>()
                .map_err(|e| format!("Failed to parse double field '{}': {} - Error: {}", field, double_str, e))?;
            doc.insert(field, Bson::Double(double_value));
        },
        Some(Bson::Int32(int_val)) => {
            // Convert integer to double
            let double_value = *int_val as f64;
            doc.insert(field, Bson::Double(double_value));
        },
        Some(Bson::Int64(int_val)) => {
            // Convert integer to double
            let double_value = *int_val as f64;
            doc.insert(field, Bson::Double(double_value));
        },
        _ => {}
    }
    
    Ok(())
}

// Re-export from MongoDbState for interface compatibility
pub use crate::mongodb_manager::MongoDbState;
// src/api_server/routes.rs

use axum::{
    routing::{get, post, put, delete},
    http::Method,
    Router,
};
use std::sync::Arc;
use tokio::sync::Mutex;
use tower_http::cors::{Any, CorsLayer};
use crate::api_server::{
    state::ApiServerState,
    handlers::{
        auth_handlers::{
            auth_login_handler,
            auth_get_me_handler,
            auth_register_handler,
            auth_check_session_handler,
        },
        collection_handlers::{
            list_collections_handler,
            get_collection_schema_handler,
            update_ui_metadata_handler,
        },
        document_handlers::{
            find_documents_handler,
            find_empty_or_recovered_documents_handler,
            find_empty_archive_history_handler,
            find_archived_documents_handler,
            find_recovered_documents_handler,
            find_pinned_documents_handler,
            insert_document_handler,
            update_document_handler,
            delete_document_handler,
            batch_delete_documents_handler,
            archive_document_handler,
            batch_archive_documents_handler,
            recover_document_handler,
            batch_recover_documents_handler,
            pin_document_handler,
            unpin_document_handler,

        },
        system_handlers::{
            health_check_handler,
            initialize_library_collections_handler,
        },
    },
};

// Create the API router and return both the router and a list of routes
pub fn create_api_router() -> (Router<Arc<Mutex<ApiServerState>>>, Vec<String>) {
    let mut routes = Vec::new();
    let mut router = Router::new();
    
    // Setup CORS
    let cors = CorsLayer::new()
        .allow_methods([Method::GET, Method::POST, Method::PUT, Method::DELETE, Method::OPTIONS])
        .allow_headers(Any)
        .allow_origin(Any);
    
    // Macro to add routes and track them
    macro_rules! add_route {
        ($method:expr, $path:expr, $handler:expr) => {
            router = match $method {
                Method::GET => router.route($path, get($handler)),
                Method::POST => router.route($path, post($handler)),
                Method::PUT => router.route($path, put($handler)),
                Method::DELETE => router.route($path, delete($handler)),
                _ => panic!("Unsupported method: {}. Update the router implementation.", $method),
            };
            routes.push(format!("{} {}", $method, $path));
        };
    }
    
    // Collection routes
    add_route!(Method::GET, "/collections", list_collections_handler);
    add_route!(Method::GET, "/collections/:collection_name/schema", get_collection_schema_handler);
    add_route!(Method::PUT, "/collections/:collection_name/ui-metadata", update_ui_metadata_handler);
    
    // Document routes
    add_route!(Method::GET, "/collections/:collection_name/documents", find_documents_handler);
    add_route!(
        Method::GET, 
        "/collections/:collection_name/empty-or-recovered", 
        find_empty_or_recovered_documents_handler
    );
    add_route!(
        Method::GET, 
        "/collections/:collection_name/empty-archive-history", 
        find_empty_archive_history_handler
    );
    add_route!(Method::GET, "/collections/:collection_name/archives", find_archived_documents_handler);
    add_route!(Method::GET, "/collections/:collection_name/recoveries", find_recovered_documents_handler);
    add_route!(Method::GET, "/collections/:collection_name/pins", find_pinned_documents_handler);
    add_route!(Method::POST, "/collections/:collection_name/documents", insert_document_handler);
    add_route!(Method::PUT, "/collections/:collection_name/documents/:id", update_document_handler);
    add_route!(Method::DELETE, "/collections/:collection_name/documents/:id", delete_document_handler);
    add_route!(
        Method::POST, 
        "/collections/:collection_name/documents/batch-delete", 
        batch_delete_documents_handler
    );
    add_route!(Method::PUT, "/collections/:collection_name/documents/:id/archive", archive_document_handler);
    add_route!(
        Method::POST, 
        "/collections/:collection_name/documents/batch-archive", 
        batch_archive_documents_handler
    );
    add_route!(Method::PUT, "/collections/:collection_name/documents/:id/recover", recover_document_handler);
    add_route!(
        Method::POST, 
        "/collections/:collection_name/documents/batch-recover", 
        batch_recover_documents_handler
    );
    add_route!(Method::PUT, "/collections/:collection_name/documents/:id/pin", pin_document_handler);
    add_route!(Method::PUT, "/collections/:collection_name/documents/:id/unpin", unpin_document_handler);
    
    // Auth routes
    add_route!(Method::POST, "/api/auth/login", auth_login_handler);
    add_route!(Method::GET, "/api/auth/me", auth_get_me_handler);
    add_route!(Method::POST, "/api/auth/register", auth_register_handler);
    add_route!(Method::POST, "/api/auth/check-session", auth_check_session_handler);
    // System routes
    add_route!(Method::POST, "/api/initialize-library-collections", initialize_library_collections_handler);
    add_route!(Method::GET, "/api/health", health_check_handler);
    
    // Apply CORS middleware
    router = router.layer(cors);
    
    (router, routes)
}
<!-- src/components/MongoDBDataTable.vue -->
<script setup lang="ts">
  // --- Script Section (Pinia Integrated) ---
  import { ref, computed, watch, onMounted, Ref, inject, nextTick, onBeforeUnmount } from 'vue'
  import { useRoute, useRouter } from 'vue-router'
  import { storeToRefs } from 'pinia'
  import { useDataTableStore } from '@/store/dataTableStore' // Make sure this path is correct
  import { useDebounceFn } from '@vueuse/core'

  // Import UI Components as used in your *original* template
  import { Cross2Icon, ReloadIcon, PlusCircledIcon } from '@radix-icons/vue' // [cite: 1]
  import { Button } from '@/components/ui/button' // [cite: 1]
  import { Input } from '@/components/ui/input' // [cite: 41]
  import { TableBody, TableCell, TableHead, TableHeader, TableRow } from '@/components/ui/table' // Used implicitly by <Table...> tags in old template
  import {
    Select,
    SelectContent,
    SelectItem,
    SelectTrigger,
    SelectValue,
  } from '@/components/ui/select' // [cite: 39, 82]
  import {
    Pagination,
    PaginationList,
    PaginationListItem,
    PaginationFirst,
    PaginationLast,
    PaginationNext,
    PaginationPrev,
  } from '@/components/ui/pagination' // [cite: 79]

  import { ScrollArea } from '@/components/ui/scroll-area' // [cite: 40]
  // Remove toast import if not used directly in setup, it's in the store
  // import { useToast } from '@/components/ui/toast/use-toast';
  import ExcelCellReference from './ExcelCellReference.vue' // [cite: 2]
  import TableActions from './mongodbtable/TableActions.vue' // [cite: 57]
  import StickyTableActions from './mongodbtable/StickyTableActions.vue' // [cite: 59]
  import MongoDBDataTableNavbar from './MongoDBDataTableNavbar.vue' // [cite: 1]
  import StickyLeftSidebar from './StickyLeftSidebar.vue'
  import { useUserStore } from '@/store/useUserStore'
  // Remove FooterTabsBar import if not used in old template
  // import FooterTabsBar from './FooterTabsBar.vue';

  // Store setup
  const dataTableStore = useDataTableStore()
  // Destructure state and getters into reactive refs
  const {
    collectionName,
    documents,
    collectionSchema,
    isLoading,
    errorMessage,
    pageSize,
    currentPage,
    newDocument,
    isAdding,
    editingCell,
    editValue,
    isSaving,
    selectedRows,
    currentView,
    pendingDeleteId,
    referenceOptions,
    loadingReferences,
    errorColumn,
    addingRowError,
    totalPages,
    paginatedDocuments,
    tableHeaders,
    columnWidths,
    allSelected,
  } = storeToRefs(dataTableStore)

  // Destructure actions (they are just functions)
  const {
    fetchCollections,
    setCollection,
    fetchDocuments,
    fetchReferenceOptions,
    getReferenceLabel,
    startAdding,
    cancelAdding,
    saveNewDocument,
    startEditingCell,
    cancelEdit,
    saveEdit,
    toggleRow,
    resetSelection,
    changeView,
    setPage, // Renamed from onPageChange
    setPageSize, // Added action
    updateColumnWidth,
    resetColumnWidth,
    saveColumnWidthsToBackend,
    clearError, // Renamed from closeError
    getSchemaInfo,
    isReferenceField,
    getReferencedCollection,
    // fetchSchema, // Optional direct access
  } = dataTableStore

  const userStore = useUserStore()
  const { user } = storeToRefs(userStore)

  // Local component state
  const route = useRoute()
  const router = useRouter()
  const isSplit = inject<Ref<boolean>>('isSplit')!
  const scrollContainer = ref<HTMLElement | null>(null) // [cite: 2]
  // const filterQuery = ref('{}'); // Kept local filter state

  const isSidebarOpen = ref(false)
  const searchQuery = ref<Record<string, string>>({}) // [cite: 41]
  const resizingState = ref({
    isResizing: false,
    header: '',
    startX: 0,
    startWidth: 0,
    currentWidth: 0,
  }) // [cite: 20]
  const alphaResizingState = ref({
    isResizing: false,
    columnIndex: -1,
    startX: 0,
    startWidth: 0,
    currentWidth: 0,
  }) // [cite: 9]
  const selectedCell = ref<{ colIndex: number; rowNumber: number } | null>(null) // [cite: 2]
  const timeoutId = ref<number | null>(null) // For error message timeout [cite: 1] - Keep or remove based on preference
  const showPinTooltip = ref(false)
  // Props
  const props = defineProps<{
    selectedCollection?: string
    name?: string
  }>()

  // --- Computed properties specific to component ---
  const getColumnLabel = (index: number): string => {
    let label = ''
    let i = index
    do {
      const remainder = i % 26
      label = String.fromCharCode(65 + remainder) + label
      i = Math.floor(i / 26) - 1
    } while (i >= 0)
    return label
  } // [cite: 9]

  const columnLetters = computed(() => {
    return tableHeaders.value.map((_, index) => getColumnLabel(index))
  }) // [cite: 9]

  const numberColumnWidth = computed(() => {
    const maxDigits = documents.value.length > 0 ? String(documents.value.length).length : 1
    return `${Math.max(3, maxDigits + 1)}ch`
  }) // [cite: 18] adjusted logic slightly

  const totalTableWidth = computed(() => {
    const dataColumnsWidth = tableHeaders.value.reduce(
      (acc, header) => acc + (columnWidths.value[header] || 200),
      0
    )
    const selectColWidth = 40 // [cite: 5]
    const rowNumColWidth = 30 // As per original template [cite: 7] - Adjust if needed
    const actionsColWidth = 60 // As per original styles [cite: 125]

    return selectColWidth + rowNumColWidth + dataColumnsWidth + actionsColWidth + 1
  }) // Adjusted calculation based on old template fixed widths

  // --- Utility Functions ---
  const isFieldRequired = (field: string): boolean => {
    return collectionSchema.value.required?.includes(field) || false
  } // [cite: 22]

  const formatSchemaValue = (value: any, bsonType?: string | string[]) => {
    if (value === undefined || value === null) return ''
    const type = bsonType ? (Array.isArray(bsonType) ? bsonType[0] : bsonType) : typeof value

    if (type === 'date' && value instanceof Date) {
      // Check if it's already a Date object
      return value.toLocaleString()
    } else if (type === 'date') {
      // Try parsing if it's not a Date object
      try {
        return new Date(value).toLocaleString()
      } catch {
        return String(value) // Fallback
      }
    }
    if (typeof value === 'object') {
      return JSON.stringify(value, null, 2) // Keep original formatting [cite: 57]
    }
    return String(value)
  } // [cite: 56, 57]

  const filteredOptions = (field: string) => {
    const refCollection = getReferencedCollection(field)
    if (!refCollection) return []
    const options = referenceOptions.value[refCollection] || []
    const query = (searchQuery.value[field] || '').toLowerCase()
    return options.filter((opt) => opt.label.toLowerCase().includes(query))
  } // [cite: 42]

  // --- Watchers ---

  // Watch route parameter 'name'
  watch(
    () => route.params.name,
    (newName) => {
      const nameStr = Array.isArray(newName) ? newName[0] : newName
      if (nameStr && nameStr !== collectionName.value) {
        setCollection(nameStr)
      }
    },
    { immediate: true }
  )

  // Watch the prop 'selectedCollection'
  watch(
    () => props.selectedCollection,
    (newVal) => {
      if (newVal && newVal !== collectionName.value) {
        setCollection(newVal)
        if (route.params.name !== newVal) {
          router.push(`/collection/${newVal}`)
        }
      }
    }
  )

  // Watch the store's collectionName to sync the route if needed
  watch(collectionName, (newName, oldName) => {
    if (newName && newName !== oldName && route.params.name !== newName) {
      router.push(`/collection/${newName}`)
    }
  })

  // Watch for error message to auto-clear (optional, kept from original logic)
  watch(errorMessage, (newVal) => {
    if (newVal) {
      if (timeoutId.value) {
        clearTimeout(timeoutId.value)
      }
      timeoutId.value = setTimeout(() => {
        clearError() // Use store action
        timeoutId.value = null
      }, 2500) as unknown as number // [cite: 1] matching timeout
    }
  })

  // Watch isAdding to prefetch reference options (kept from original logic)
  watch(isAdding, async (newVal) => {
    if (newVal) {
      tableHeaders.value.forEach((field) => {
        // Use tableHeaders getter
        const refCollection = getReferencedCollection(field)
        if (refCollection && !referenceOptions.value[refCollection]) {
          fetchReferenceOptions(refCollection) // Use store action
        }
      })
    }
  }) // [cite: 67] reference fetching logic

  // --- Lifecycle Hooks ---
  onMounted(async () => {
    console.log('MongoDBDataTable mounted (Pinia + Old Style).')

    // Add user ID logging
    if (user.value) {
      console.log('User ID:', user.value.id)
    } else {
      console.log('User not authenticated')
    }

    await fetchCollections()
    const routeName = Array.isArray(route.params.name) ? route.params.name[0] : route.params.name
    const initialCollection = routeName || props.selectedCollection

    if (
      initialCollection &&
      typeof initialCollection === 'string' &&
      initialCollection !== collectionName.value
    ) {
      await setCollection(initialCollection)
    } else if (collectionName.value && documents.value.length === 0 && !isLoading.value) {
      try {
        await dataTableStore.fetchSchema()
        await dataTableStore.fetchDocuments()
      } catch (error) {
        console.error('Error fetching initial schema/documents in onMounted:', error)
      }
    }
  })

  // --- Methods ---

  // Error closing (if keeping the manual close button)
  const closeErrorManual = () => {
    if (timeoutId.value) {
      clearTimeout(timeoutId.value)
      timeoutId.value = null
    }
    clearError() // Use store action
  } // Matches original @click="closeError" [cite: 1]

  // Debounced function for saving widths
  const debouncedSaveWidths = useDebounceFn(async () => {
    await saveColumnWidthsToBackend() // Call store action
  }, 750) // Keep debounce consistent

  // --- Column Resizing Handlers ---
  // These call store actions now but retain the local state for visual feedback during drag

  const startAlphaResize = (columnIndex: number, event: MouseEvent) => {
    const header = tableHeaders.value[columnIndex] // Use getter
    if (!header) return
    const currentWidth = columnWidths.value[header] || 200 // Use getter

    alphaResizingState.value = {
      isResizing: true,
      columnIndex,
      startX: event.clientX,
      startWidth: currentWidth,
      currentWidth: currentWidth,
    }
    document.addEventListener('mousemove', handleAlphaMouseMove)
    document.addEventListener('mouseup', stopAlphaResize)
    event.preventDefault()
  } // [cite: 14]

  const handleAlphaMouseMove = (event: MouseEvent) => {
    if (!alphaResizingState.value.isResizing) return
    const delta = event.clientX - alphaResizingState.value.startX
    const newWidth = Math.max(50, alphaResizingState.value.startWidth + delta)
    alphaResizingState.value.currentWidth = newWidth

    const header = tableHeaders.value[alphaResizingState.value.columnIndex]
    if (header && collectionSchema.value.ui) {
      // Temporarily update local schema for visual feedback
      collectionSchema.value.ui.columnWidths = {
        ...collectionSchema.value.ui.columnWidths,
        [header]: newWidth,
      }
    }
  }

  const stopAlphaResize = async () => {
    if (!alphaResizingState.value.isResizing) return
    const header = tableHeaders.value[alphaResizingState.value.columnIndex]
    const finalWidth = alphaResizingState.value.currentWidth
    alphaResizingState.value.isResizing = false
    document.removeEventListener('mousemove', handleAlphaMouseMove)
    document.removeEventListener('mouseup', stopAlphaResize)

    if (header) {
      await updateColumnWidth(header, finalWidth) // Update store
      debouncedSaveWidths() // Trigger debounced save
    }
  }

  const resetAlphaColumnWidth = async (columnIndex: number) => {
    const header = tableHeaders.value[columnIndex]
    if (header) {
      await resetColumnWidth(header) // Update store
      debouncedSaveWidths() // Trigger save
    }
  } // [cite: 14]

  const startResize = (header: string, event: MouseEvent) => {
    const currentWidth = columnWidths.value[header] || 200
    resizingState.value = {
      isResizing: true,
      header,
      startX: event.clientX,
      startWidth: currentWidth,
      currentWidth: currentWidth,
    }
    document.addEventListener('mousemove', handleMouseMove)
    document.addEventListener('mouseup', stopResize)
    event.preventDefault()
  } // [cite: 25]

  const handleMouseMove = (event: MouseEvent) => {
    if (!resizingState.value.isResizing) return
    const delta = event.clientX - resizingState.value.startX
    const newWidth = Math.max(50, resizingState.value.startWidth + delta)
    resizingState.value.currentWidth = newWidth

    const header = resizingState.value.header
    if (header && collectionSchema.value.ui) {
      // Temporarily update local schema for visual feedback
      collectionSchema.value.ui.columnWidths = {
        ...collectionSchema.value.ui.columnWidths,
        [header]: newWidth,
      }
    }
  }

  const stopResize = async () => {
    if (!resizingState.value.isResizing) return
    const header = resizingState.value.header
    const finalWidth = resizingState.value.currentWidth
    resizingState.value.isResizing = false
    document.removeEventListener('mousemove', handleMouseMove)
    document.removeEventListener('mouseup', stopResize)

    if (header) {
      await updateColumnWidth(header, finalWidth) // Update store
      debouncedSaveWidths() // Trigger save
    }
  }

  // const resetColumnWidth = async (header: string) => { // Renamed from original resetDataColumnWidth for clarity
  //   await resetColumnWidth(header); // Call store action (make sure names don't clash)
  //   debouncedSaveWidths();
  // }; // [cite: 25]

  // --- Cell Click/Edit Handling ---

  const handleCellClick = (rowIndex: number, header: string, value: any) => {
    // Value param from original template [cite: 52]
    if (isSaving.value || ['_id', 'created_at', 'updated_at'].includes(header)) return

    // Use the original value passed from the template click event
    startEditingCell(rowIndex, header, value) // Use store action

    // Update selectedCell for visual feedback (Excel-like)
    const actualRowNumber = (currentPage.value - 1) * pageSize.value + rowIndex + 1
    const colIndex = tableHeaders.value.indexOf(header)
    selectedCell.value = { colIndex, rowNumber: actualRowNumber } // [cite: 2]

    // Focus logic can be kept if desired
    nextTick(() => {
      // Simplified focus selector - adjust if needed
      const inputElement = scrollContainer.value?.querySelector<
        HTMLInputElement | HTMLTextAreaElement
      >(
        `tr:nth-child(${rowIndex + 1}) td[class*='excel-cell'] textarea, tr:nth-child(${rowIndex + 1}) td[class*='excel-cell'] input`
      )
      inputElement?.focus()
      if (inputElement && (inputElement.tagName === 'TEXTAREA' || inputElement.type === 'text')) {
        inputElement.select()
      }
    })
  } // Combines original template call [cite: 52] with store logic

  // Handle blur event on editable inputs/textareas - uses store action
  const handleEditBlur = async () => {
    setTimeout(async () => {
      const activeElement = document.activeElement
      // Basic check if focus is still within the editing area (might need refinement)
      const isStillEditing =
        editingCell.value &&
        activeElement &&
        (activeElement.closest('.excel-cell-selected') ||
          activeElement.closest('[data-radix-popper-content-wrapper]')) // Consider Radix poppers for Select

      if (editingCell.value && !isStillEditing) {
        await saveEdit() // Use store action
      } else if (!isStillEditing) {
        cancelEdit() // Use store action
      }
    }, 100)
  } // Connects to @blur event [cite: 50]

  // --- Template specific handlers ---
  // Handle view change from ExcelCellReference component
  const handleViewChange = (view: string) => {
    changeView(view) // Use store action
  } // [cite: 4]

  // Handler for pagination component update event
  const onPageChange = (page: number) => {
    setPage(page) // Use store action
  } // [cite: 79]

  // Handlers for delete start/end from actions components
  const handleDeleteStart = (id: string) => {
    dataTableStore.pendingDeleteId = id
  } // [cite: 3, 58, 60]
  const handleDeleteEnd = () => {
    dataTableStore.pendingDeleteId = null
  } // [cite: 4, 59, 60]

  // Expose methods (less common with Pinia but kept if original template needed it)
  defineExpose({
    fetchDocuments: dataTableStore.fetchDocuments,
    fetchCollections: dataTableStore.fetchCollections,
    setCollection: dataTableStore.setCollection,
  })

  const showContextMenu = ref(false)
  const contextMenuPosition = ref({ x: 0, y: 0 })
  const selectedCellInfo = ref<{ rowIndex: number; header: string } | null>(null)

  // methods for context menu
  const handleRightClick = (rowIndex: number, header: string, event: MouseEvent) => {
    event.preventDefault()
    selectedCellInfo.value = { rowIndex, header }

    // Calculate actual row number and column index for highlighting
    const actualRowNumber = (currentPage.value - 1) * pageSize.value + rowIndex + 1
    const colIndex = tableHeaders.value.indexOf(header)
    selectedCell.value = { colIndex, rowNumber: actualRowNumber }

    // Position context menu
    const offset = 55
    contextMenuPosition.value = {
      x: event.clientX,
      y: event.clientY - offset,
    }
    showContextMenu.value = true
  }

  const closeContextMenu = () => {
    showContextMenu.value = false
    selectedCellInfo.value = null
  }

  const pinCell = async () => {
    console.log('pinCell: Function called')
    if (!selectedCellInfo.value) {
      console.warn('pinCell: No cell selected')
      return
    }
    if (isSelectedArchived.value) {
      console.warn('pinCell: Selected document is archived, cannot pin/unpin')
      return
    }
    // Add check for null user
    if (!user.value) {
      console.warn('pinCell: User not authenticated')
      return
    }
    const rowIndex = selectedCellInfo.value.rowIndex
    console.log(`pinCell: Selected row index: ${rowIndex}`)
    const doc = paginatedDocuments.value[rowIndex]
    if (!doc) {
      console.warn(`pinCell: No document found at row index ${rowIndex}`)
      return
    }
    const isPinned = doc.pinned_by?.includes(user.value.id)
    console.log(
      `pinCell: Document ID: ${doc._id.$oid}, Current pin state: ${isPinned ? 'pinned' : 'unpinned'}`
    )
    try {
      if (isPinned) {
        console.log(`pinCell: Document is currently pinned, attempting to unpin`)
        await dataTableStore.unpinDocument(doc._id.$oid)
        console.log(`pinCell: Unpin operation completed`)
      } else {
        console.log(`pinCell: Document is currently unpinned, attempting to pin`)
        await dataTableStore.pinDocument(doc._id.$oid)
        console.log(`pinCell: Pin operation completed`)
      }

      // Add this critical line to refresh documents after pin/unpin operation
      console.log('pinCell: Refreshing documents to ensure pin state consistency across users')
      await dataTableStore.fetchDocuments()
      console.log('pinCell: Document refresh completed')
    } catch (error) {
      console.error('pinCell: Pin/Unpin error:', error)
    }
    console.log('pinCell: Closing context menu')
    closeContextMenu()
  }

  const bookmarkCell = () => {
    if (!selectedCellInfo.value) return
    console.log('Bookmarking cell:', selectedCellInfo.value)
    closeContextMenu()
  }

  // Add window click listener (in onMounted)
  onMounted(() => {
    window.addEventListener('click', closeContextMenu)
  })

  // Add cleanup (if using beforeUnmount)
  onBeforeUnmount(() => {
    window.removeEventListener('click', closeContextMenu)
  })
  const isSelectedArchived = computed(() => {
    console.log('Computing isSelectedArchived')

    if (!selectedCellInfo.value) {
      console.log('No selectedCellInfo, returning false')
      return false
    }

    const rowIndex = selectedCellInfo.value.rowIndex
    console.log('Selected row index:', rowIndex)

    const document = paginatedDocuments.value[rowIndex]
    console.log('Selected document:', document)

    const isArchived = document?.is_archive === true
    console.log('Is document archived:', isArchived)

    return isArchived
  })

  const selectedDocumentIsPinned = computed(() => {
    if (!selectedCellInfo.value) return false
    if (!user.value) return false // Add this check for null user

    const doc = paginatedDocuments.value[selectedCellInfo.value.rowIndex]
    return doc?.pinned_by?.includes(user.value.id)
  })

  const togglePinStatus = async (docId: string, currentPinStatus: boolean): Promise<void> => {
    try {
      if (currentPinStatus) {
        await dataTableStore.unpinDocument(docId)
      } else {
        await dataTableStore.pinDocument(docId)
      }
    } catch (error) {
      console.error('Error toggling pin status:', error)
    }
  }

  // --- New Computed Property ---
  const pinnedDocuments = computed(() => {
    if (!user.value) return []
    return documents.value.filter((doc) => doc.pinned_by?.includes(user.value?.id))
  })

  // --- New Watcher ---
  const debouncedLogPinnedDocuments = useDebounceFn((newVal) => {
    console.log('Pinned Documents:', newVal)
  }, 500)

  watch(pinnedDocuments, (newVal) => debouncedLogPinnedDocuments(newVal), {
    immediate: true,
    deep: true,
  })

  const highlightedDocumentId = ref<string | null>(null)
  let highlightTimeout: ReturnType<typeof setTimeout> | null = null

  const handleDocumentNavigation = (docId: string) => {
    // Clear existing timeout if any
    if (highlightTimeout) clearTimeout(highlightTimeout)

    // Find document index in full dataset
    const index = documents.value.findIndex((doc) => doc._id.$oid === docId)
    if (index === -1) return

    // Calculate and set correct page
    const page = Math.ceil((index + 1) / pageSize.value)
    setPage(page)

    // Set highlight and auto-clear after 3s
    highlightedDocumentId.value = docId
    highlightTimeout = setTimeout(() => {
      highlightedDocumentId.value = null
    }, 2000)

    // Scroll to row after DOM update
    nextTick(() => {
      const row = scrollContainer.value?.querySelector(`[data-document-id="${docId}"]`)
      if (row) {
        row.scrollIntoView({
          behavior: 'smooth',
          block: 'nearest',
          inline: 'nearest',
        })

        // Add visual pulse effect
        row.classList.add('highlight-pulse')
        setTimeout(() => row.classList.remove('highlight-pulse'), 1000)
      }
    })
  }

  // row resizing state
  const rowResizingState = ref({
    isResizing: false,
    documentId: '',
    startY: 0,
    startHeight: 40, // Default row height
    currentHeight: 40,
  })

  const startRowResize = (documentId: string, event: MouseEvent) => {
    const doc = documents.value.find((d) => d._id.$oid === documentId)
    if (!doc) return

    const currentHeight = doc.row_height || 40
    rowResizingState.value = {
      isResizing: true,
      documentId,
      startY: event.clientY,
      startHeight: currentHeight,
      currentHeight,
    }

    document.addEventListener('mousemove', handleRowMouseMove)
    document.addEventListener('mouseup', stopRowResize)
  }

  const handleRowMouseMove = (event: MouseEvent) => {
    if (!rowResizingState.value.isResizing) return

    const delta = event.clientY - rowResizingState.value.startY
    const newHeight = Math.max(40, rowResizingState.value.startHeight + delta)

    rowResizingState.value.currentHeight = newHeight

    // Update local document for visual feedback
    const docIndex = documents.value.findIndex(
      (d) => d._id.$oid === rowResizingState.value.documentId
    )
    if (docIndex !== -1) {
      const updatedDoc = {
        ...documents.value[docIndex],
        row_height: newHeight,
      }
      documents.value.splice(docIndex, 1, updatedDoc)
    }
  }

  // Row height debouncing
  const debouncedRowHeightSave = useDebounceFn(async (documentId: string, height: number) => {
    try {
      await dataTableStore.updateDocumentField(documentId, 'row_height', height)
    } catch (error) {
      console.error('Error saving row height:', error)
    }
  }, 500) // 500ms delay

  const stopRowResize = async () => {
    if (!rowResizingState.value.isResizing) return
    const { documentId, currentHeight } = rowResizingState.value

    rowResizingState.value.isResizing = false
    document.removeEventListener('mousemove', handleRowMouseMove)
    document.removeEventListener('mouseup', stopRowResize)

    // Use debounced save instead of immediate
    debouncedRowHeightSave(documentId, currentHeight)
  }
</script>

<template>
  <!-- MongoDBDataTable main div -->
  <div
    :class="isSidebarOpen ? 'ml-[280px]' : 'ml-0'"
    class="transition-all duration-300 ease-in-out"
  >
    <MongoDBDataTableNavbar
      :isSplitActive="isSplit"
      class="sticky top-0 z-50"
    />
    <div class="excel-container w-full">
      <StickyLeftSidebar
        :isOpen="isSidebarOpen"
        :pinnedDocuments="pinnedDocuments"
        @toggle="isSidebarOpen = !isSidebarOpen"
        @navigate="handleDocumentNavigation"
      />
      <div
        v-if="errorMessage"
        class="fixed top-4 left-4 right-4 z-[9999] mx-4 my-4 p-4 bg-red-100 text-red-700 rounded-lg shadow-xl border-2 border-red-300 break-words"
      >
        {{ errorMessage }}
        <Button
          @click="closeErrorManual"
          variant="ghost"
          size="sm"
          class="absolute right-3 top-3 p-1 h-6 w-6 text-red-700 hover:bg-red-200"
        >
          <Cross2Icon class="h-3 w-3" />
        </Button>
      </div>

      <div
        v-if="isLoading"
        class="flex justify-center my-8"
      >
        <ReloadIcon class="h-8 w-8 animate-spin text-gray-500" />
      </div>

      <div
        ref="scrollContainer"
        class="w-full overflow-auto table-scroll-container"
      >
        <ExcelCellReference
          :is-sidebar-open="isSidebarOpen"
          :selected-cell="selectedCell"
          :selected-rows="selectedRows"
          :collection-name="collectionName"
          :documents="documents"
          :current-page="currentPage"
          :page-size="pageSize"
          :current-view="currentView"
          @document-deleted="fetchDocuments"
          @reset-selection="resetSelection"
          @delete-start="handleDeleteStart"
          @delete-end="handleDeleteEnd"
          @view-change="handleViewChange"
        />
        <table
          class="mt-10 excel-table"
          :style="{ width: `${totalTableWidth}px` }"
        >
          <TableHeader>
            <TableRow class="excel-header-row">
              <TableHead
                class="excel-column-checkbox-selector"
                :style="{
                  width: '40px',
                  minWidth: '40px',
                  maxWidth: '40px',
                }"
              >
                <input
                  type="checkbox"
                  :checked="allSelected"
                  @change="allSelected = !allSelected"
                  :disabled="documents.length === 0"
                  class="excel-checkbox"
                />
              </TableHead>

              <TableHead
                class="excel-column-checkbox"
                :style="{
                  width: '30px',
                  minWidth: '30px',
                  maxWidth: '30px',
                }"
              >
                @
              </TableHead>
              <TableHead
                v-for="(letter, index) in columnLetters"
                :key="`letter-${index}`"
                class="excel-column-letter relative"
                :style="{
                  width:
                    alphaResizingState.isResizing && alphaResizingState.columnIndex === index
                      ? `${alphaResizingState.currentWidth}px`
                      : `${columnWidths[tableHeaders[index]] || 200}px`,
                }"
              >
                <div class="flex items-center justify-center">
                  <span class="excel-letter">{{ letter }}</span>
                  <div
                    class="excel-resizer absolute right-0 top-0"
                    :class="[
                      alphaResizingState.isResizing && alphaResizingState.columnIndex === index
                        ? 'excel-resizer-active'
                        : '',
                    ]"
                    @mousedown="startAlphaResize(index, $event)"
                    @dblclick="resetAlphaColumnWidth(index)"
                  ></div>
                </div>
              </TableHead>
              <TableHead class="excel-column-letter excel-actions-header w-24"> </TableHead>
            </TableRow>
          </TableHeader>
          <TableHeader>
            <TableRow>
              <TableHead
                class="excel-column-checkbox-selector"
                :style="{
                  width: '40px',
                  minWidth: '40px',
                  maxWidth: '40px',
                }"
              >
                ***
              </TableHead>

              <TableHead
                class="excel-row-number-header"
                :style="{
                  width: numberColumnWidth,
                  minWidth: numberColumnWidth,
                  maxWidth: numberColumnWidth,
                }"
              >
                &-
              </TableHead>
              <TableHead
                v-for="header in tableHeaders"
                :key="header"
                class="excel-column-header font-bold text-black relative"
                :class="{ 'error-column-header': header === errorColumn && isAdding }"
                :style="{
                  width:
                    resizingState.isResizing && resizingState.header === header
                      ? `${resizingState.currentWidth}px`
                      : `${columnWidths[header] || 200}px`,
                }"
              >
                <div class="flex items-center justify-between">
                  <span>
                    {{ header }}
                    <span
                      v-if="isFieldRequired(header)"
                      class="text-red-500"
                      >*</span
                    >
                  </span>
                  <div
                    class="excel-resizer absolute right-0 top-0"
                    :class="[
                      resizingState.isResizing && resizingState.header === header
                        ? 'excel-resizer-active'
                        : '',
                    ]"
                    @mousedown="startResize(header, $event)"
                    @dblclick="resetColumnWidth(header)"
                  ></div>
                </div>
              </TableHead>
              <TableHead
                class="excel-column-header excel-actions-header select-none"
                :style="{ width: '30px' }"
              >
                Actions
              </TableHead>
            </TableRow>
          </TableHeader>
          <TableBody>
            <template v-if="documents.length > 0">
              <TableRow
                v-for="(doc, rowIndex) in paginatedDocuments"
                :key="doc._id.$oid"
                :data-document-id="doc._id.$oid"
                :style="{ height: (doc.row_height || 40) + 'px' }"
                class="excel-data-row relative"
                :class="{
                  'highlight-row': highlightedDocumentId === doc._id.$oid,
                  'bg-red-100 border-2 border-red-500 text-red-800':
                    doc._id.$oid === pendingDeleteId,
                  'selected-row bg-blue-100':
                    selectedRows.has(doc._id.$oid) && doc._id.$oid !== pendingDeleteId,
                }"
              >
                <TableCell
                  class="excel-column-checkbox-selector"
                  :style="{
                    width: '40px',
                    minWidth: '40px',
                    maxWidth: '40px',
                  }"
                >
                  <input
                    type="checkbox"
                    :checked="selectedRows.has(doc._id.$oid)"
                    @change="toggleRow(doc._id.$oid)"
                    class="excel-checkbox"
                  />
                </TableCell>
                <TableCell
                  class="excel-row-number relative"
                  :style="{
                    width: numberColumnWidth,
                    minWidth: numberColumnWidth,
                    maxWidth: numberColumnWidth,
                  }"
                >
                  <div
                    class="w-full h-full flex items-center justify-center cursor-pointer relative"
                    @click.stop="
                      togglePinStatus(doc._id.$oid, user && doc.pinned_by?.includes(user.id))
                    "
                    :class="{ 'hover:bg-gray-100': !doc.is_archive }"
                    :title="
                      doc.is_archive
                        ? 'Cannot pin/unpin archived items'
                        : user && doc.pinned_by?.includes(user.id)
                          ? 'Click to unpin'
                          : 'Click to pin'
                    "
                  >
                    <span class="">{{ (currentPage - 1) * pageSize + rowIndex + 1 }}</span>

                    <span
                      v-if="user && doc.pinned_by?.includes(user.id)"
                      class="text-xl left-2 bottom-2 absolute z-10"
                    >
                      
                    </span>
                  </div>

                  <!-- Row resize handle -->
                  <div
                    class="row-resize-handle absolute bottom-[-1px] left-0 right-0 h-2 cursor-row-resize z-10"
                    @mousedown.prevent="startRowResize(doc._id.$oid, $event)"
                  ></div>
                </TableCell>
                <TableCell
                  v-for="header in tableHeaders"
                  :key="`${doc._id.$oid}-${header}`"
                  class="excel-cell"
                  :class="{
                    'error-column-cell': header === errorColumn,
                    'excel-cell-selected':
                      editingCell?.rowIndex === rowIndex && editingCell?.header === header,
                    'excel-cell-context-selected':
                      selectedCellInfo?.rowIndex === rowIndex &&
                      selectedCellInfo?.header === header,
                  }"
                  @contextmenu.prevent="handleRightClick(rowIndex, header, $event)"
                >
                  <div class="h-full">
                    <div
                      v-if="editingCell?.rowIndex === rowIndex && editingCell?.header === header"
                      class="h-full"
                    >
                      <div
                        v-if="getSchemaInfo(header).bsonType === 'bool'"
                        class="flex items-center justify-center h-full p-2"
                      >
                        <input
                          type="checkbox"
                          v-model="editValue"
                          @change="saveEdit"
                          class="excel-checkbox"
                        />
                      </div>
                      <div
                        v-else-if="isReferenceField(header)"
                        class="p-1"
                      >
                        <Select
                          v-model="editValue"
                          @update:modelValue="saveEdit"
                          class="excel-select"
                        >
                          <SelectTrigger>
                            <SelectValue
                              :placeholder="`Select ${getReferencedCollection(header)}`"
                              :model-value="editValue"
                            />
                          </SelectTrigger>
                          <SelectContent>
                            <ScrollArea class="h-48">
                              <div class="p-1">
                                <Input
                                  v-model="searchQuery[header]"
                                  placeholder="Search..."
                                  class="mb-2 excel-input"
                                />
                                <div
                                  v-if="loadingReferences[getReferencedCollection(header)!]"
                                  class="text-center p-2"
                                >
                                  <ReloadIcon class="h-4 w-4 animate-spin" />
                                </div>
                                <div v-else-if="filteredOptions(header).length">
                                  <SelectItem
                                    v-for="option in filteredOptions(header)"
                                    :key="option.id"
                                    :value="option.id"
                                  >
                                    {{ option.label }}
                                  </SelectItem>
                                </div>
                                <div
                                  v-else
                                  class="text-sm text-gray-500 px-2 py-1"
                                >
                                  No options found
                                </div>
                              </div>
                            </ScrollArea>
                          </SelectContent>
                        </Select>
                      </div>
                      <Input
                        v-else-if="getSchemaInfo(header).bsonType === 'date'"
                        type="datetime-local"
                        v-model="editValue"
                        @blur="handleEditBlur"
                        class="excel-input excel-date-input"
                      />
                      <textarea
                        v-else
                        v-model="editValue"
                        @blur="handleEditBlur"
                        @keyup.ctrl.enter="saveEdit"
                        @keyup.esc="cancelEdit"
                        class="excel-textarea"
                        rows="1"
                      ></textarea>
                    </div>
                    <div
                      v-else
                      class="excel-cell-content"
                      :class="{
                        'excel-cell-editable': !['_id', 'created_at', 'updated_at'].includes(
                          header
                        ),
                        'excel-cell-readonly': ['_id', 'created_at', 'updated_at'].includes(header),
                      }"
                      @click="handleCellClick(rowIndex, header, doc[header])"
                    >
                      <div
                        v-if="getSchemaInfo(header).bsonType === 'bool'"
                        class="flex justify-center"
                      >
                        <input
                          type="checkbox"
                          :checked="doc[header]"
                          disabled
                          class="excel-checkbox"
                        />
                      </div>
                      <div
                        v-else-if="isReferenceField(header)"
                        class="excel-reference-value"
                      >
                        <span v-if="loadingReferences[getReferencedCollection(header)!]">...</span>
                        <span v-else>{{
                          getReferenceLabel(header, doc[header]) || doc[header]
                        }}</span>
                      </div>
                      <template v-else-if="['created_at', 'updated_at'].includes(header)">
                        <span class="excel-timestamp">
                          {{ formatSchemaValue(doc[header], getSchemaInfo(header).bsonType) }}
                        </span>
                      </template>
                      <template v-else-if="header === '_id'">
                        <span>{{ doc[header]?.$oid || doc[header] }}</span>
                      </template>
                      <template v-else>
                        {{ formatSchemaValue(doc[header], getSchemaInfo(header).bsonType) }}
                      </template>
                    </div>
                  </div>
                </TableCell>
                <TableActions
                  :collection-name="collectionName"
                  :document-id="doc._id.$oid"
                  :row-number="(currentPage - 1) * pageSize + rowIndex + 1"
                  @deleted="fetchDocuments"
                  @delete-start="handleDeleteStart"
                  @delete-end="handleDeleteEnd"
                />
                <StickyTableActions
                  :collection-name="collectionName"
                  :document-id="doc._id.$oid"
                  :row-number="(currentPage - 1) * pageSize + rowIndex + 1"
                  :target-ref="scrollContainer"
                  :is-last-row="rowIndex === paginatedDocuments.length - 1"
                  :is-single-row="paginatedDocuments.length === 1"
                  @deleted="fetchDocuments"
                  @delete-start="handleDeleteStart"
                  @delete-end="handleDeleteEnd"
                />
              </TableRow>

              <!-- Context Menu -->
              <div
                v-if="showContextMenu"
                class="fixed z-50 bg-white shadow-lg border rounded-md p-1 min-w-[120px] context-menu"
                :style="{
                  left: `${contextMenuPosition.x}px`,
                  top: `${contextMenuPosition.y}px`,
                }"
                @click="closeContextMenu"
              >
                <div
                  class="flex items-center px-3 py-1.5 text-sm rounded-sm relative tooltip-container"
                  :class="[
                    isSelectedArchived
                      ? 'text-gray-400 cursor-not-allowed'
                      : 'hover:bg-gray-100 cursor-pointer text-gray-700',
                  ]"
                  @click="pinCell"
                  @mouseenter="isSelectedArchived && (showPinTooltip = true)"
                  @mouseleave="showPinTooltip = false"
                >
                  <span>
                    <template v-if="selectedDocumentIsPinned"> Unpin this item</template>
                    <template v-else> Pin this item</template>
                  </span>
                  <!-- Custom tooltip -->
                  <div
                    v-if="isSelectedArchived && showPinTooltip"
                    class="custom-tooltip absolute bg-gray-800 text-white text-xs rounded py-1 px-2 left-0 bottom-full mb-1 whitespace-nowrap pointer-events-none z-50"
                  >
                    You cannot pin an archived item
                    <div
                      class="tooltip-arrow absolute top-full left-4 w-2 h-2 bg-gray-800 transform rotate-45"
                    ></div>
                  </div>
                </div>
                <div
                  class="flex items-center px-3 py-1.5 text-sm hover:bg-gray-100 rounded-sm cursor-pointer"
                  @click="bookmarkCell"
                >
                   Bookmark
                </div>
              </div>

              <!-- End of Context Menu -->
            </template>

            <TableRow
              v-if="isAdding"
              class="excel-new-row"
              :class="['excel-new-row', { 'excel-new-row-error': addingRowError }]"
            >
              <TableCell
                class="excel-column-checkbox-selector"
                :style="{
                  width: '40px',
                  minWidth: '40px',
                  maxWidth: '40px',
                }"
              >
                <input
                  type="checkbox"
                  disabled
                  class="excel-checkbox"
                />
              </TableCell>
              <TableCell class="excel-row-number"> {{ documents.length + 1 }} </TableCell>
              <TableCell
                v-for="header in tableHeaders"
                :key="`new-${header}`"
                class="excel-cell"
                :class="{ 'error-column-cell': header === errorColumn }"
              >
                <span
                  v-if="['created_at', 'updated_at'].includes(header)"
                  class="excel-timestamp"
                >
                  (auto-generated)
                </span>

                <div
                  v-else-if="header !== '_id' && getSchemaInfo(header).bsonType === 'bool'"
                  class="flex items-center justify-center"
                >
                  <input
                    type="checkbox"
                    v-model="newDocument[header]"
                    class="excel-checkbox"
                  />
                </div>
                <div
                  v-else-if="header !== '_id' && isReferenceField(header)"
                  class="h-8"
                >
                  <Select
                    v-model="newDocument[header]"
                    class="excel-select"
                  >
                    <SelectTrigger class="h-8">
                      <SelectValue :placeholder="`Select`" />
                    </SelectTrigger>
                    <SelectContent>
                      <div
                        v-if="loadingReferences[getReferencedCollection(header)!]"
                        class="p-2"
                      >
                        <ReloadIcon class="h-4 w-4 animate-spin mx-auto" />
                      </div>
                      <ScrollArea
                        v-else
                        class="h-48"
                      >
                        <Input
                          v-model="searchQuery[header]"
                          placeholder="Search..."
                          class="mb-1 mx-1 excel-input"
                        />
                        <SelectItem
                          v-for="option in filteredOptions(header)"
                          :key="option.id"
                          :value="option.id"
                        >
                          {{ option.label }}
                        </SelectItem>
                      </ScrollArea>
                    </SelectContent>
                  </Select>
                </div>
                <Input
                  v-else-if="header !== '_id'"
                  v-model="newDocument[header]"
                  :type="getSchemaInfo(header).bsonType === 'date' ? 'datetime-local' : 'text'"
                  class="excel-input"
                  :class="{ 'ring-2 ring-red-500': header === errorColumn }"
                />
                <span
                  v-else
                  class="excel-auto-id"
                  >(auto)</span
                >
              </TableCell>
              <TableCell class="excel-cell text-center">
                <Button
                  variant="ghost"
                  @click="saveNewDocument"
                  size="sm"
                  class="px-0 -ml-1"
                  :disabled="isSaving"
                >
                  <ReloadIcon
                    v-if="isSaving"
                    class="h-4 w-4 animate-spin"
                  />
                  <span v-else></span>
                </Button>
              </TableCell>
            </TableRow>

            <TableRow
              v-if="!isAdding"
              class="excel-add-row"
              @click="startAdding"
            >
              <TableCell
                :colspan="tableHeaders.length + 3"
                class="excel-add-cell"
              >
                <div class="inline-flex items-center gap-2 excel-add-button">
                  <PlusCircledIcon class="h-4 w-4" />
                  <span class="text-sm">
                    {{ documents.length === 0 ? 'Add first document' : 'Add new document' }}
                  </span>
                </div>
              </TableCell>
            </TableRow>
          </TableBody>
        </table>

        <div
          v-if="isAdding"
          class="sticky top-2 left-2 z-20 p-3 shadow-lg flex items-center space-x-2 w-auto rounded-md bg-green-50"
        >
          <Button
            @click="saveNewDocument"
            size="sm"
            class="bg-green-600 hover:bg-green-700 text-white"
            :disabled="isSaving"
          >
            <ReloadIcon
              v-if="isSaving"
              class="w-4 h-4 animate-spin"
            />
            <PlusCircledIcon
              v-else
              class="w-4 h-4 mr-1"
            />
            Save
          </Button>
          <Button
            @click="cancelAdding"
            variant="outline"
            size="sm"
            class="border-green-600 text-green-700 hover:bg-green-100"
            :disabled="isSaving"
          >
            <Cross2Icon class="w-4 h-4 mr-1" /> Cancel
          </Button>
        </div>

        <div
          v-if="totalPages > 1"
          class="excel-pagination"
        >
          <Pagination
            :page="currentPage"
            :itemsPerPage="pageSize"
            :total="documents.length"
            @update:page="onPageChange"
            :siblingCount="1"
          >
            <PaginationList>
              <PaginationListItem :value="1">
                <PaginationFirst
                  :disabled="currentPage === 1"
                  @click="setPage(1)"
                  class="excel-pagination-button"
                />
              </PaginationListItem>
              <PaginationListItem :value="Math.max(1, currentPage - 1)">
                <PaginationPrev
                  :disabled="currentPage === 1"
                  @click="setPage(currentPage - 1)"
                  class="excel-pagination-button"
                />
              </PaginationListItem>
              <PaginationListItem :value="Math.min(totalPages, currentPage + 1)">
                <PaginationNext
                  :disabled="currentPage === totalPages"
                  @click="setPage(currentPage + 1)"
                  class="excel-pagination-button"
                />
              </PaginationListItem>
              <PaginationListItem :value="totalPages">
                <PaginationLast
                  :disabled="currentPage === totalPages"
                  @click="setPage(totalPages)"
                  class="excel-pagination-button"
                />
              </PaginationListItem>
            </PaginationList>
          </Pagination>
        </div>

        <div
          v-if="!isAdding"
          class="excel-footer"
        >
          <span class="excel-page-size-label">Rows per page:</span>
          <Select
            :modelValue="String(pageSize)"
            @update:modelValue="(val) => setPageSize(Number(val))"
            class="excel-page-size-select"
          >
            <SelectTrigger class="w-16"> <SelectValue /> </SelectTrigger>
            <SelectContent>
              <SelectItem value="5">5</SelectItem> <SelectItem value="10">10</SelectItem>
              <SelectItem value="20">20</SelectItem> <SelectItem value="50">50</SelectItem>
              <SelectItem value="100">100</SelectItem>
            </SelectContent>
          </Select>

          <span class="excel-status-info">
            Showing {{ paginatedDocuments.length ? (currentPage - 1) * pageSize + 1 : 0 }} to
            {{ (currentPage - 1) * pageSize + paginatedDocuments.length }} of
            {{ documents.length }} entries
          </span>
        </div>
      </div>
    </div>
  </div>
</template>

<style scoped>
  .row-resize-handle {
    background-color: transparent;
    transition: background-color 0.2s;
  }

  .row-resize-handle:hover {
    background-color: #3b82f6;
  }

  .excel-data-row:hover .row-resize-handle {
    background-color: #3b82f666;
  }

  .highlight-row {
    position: relative;
    animation: highlight-fade 2s forwards;
    box-shadow: 0 0 0 2px #fde047; /* Outline yellow */
    outline: 2px solid #fde047; /* Same as box shadow */
    background-color: #fff9c4; /* Lighter yellow background */
  }

  @keyframes highlight-fade {
    0% {
      box-shadow: 0 0 0 3px #fde047;
    }
    70% {
      box-shadow: 0 0 0 3px #fde047;
    }
    100% {
      box-shadow: 0 0 0 3px transparent;
    }
  }

  .highlight-pulse {
    animation: pulse-highlight 1s ease-in-out;
  }

  @keyframes pulse-highlight {
    0% {
      transform: scale(1);
    }
    50% {
      transform: scale(1.02);
    }
    100% {
      transform: scale(1);
    }
  }

  /* Context Menu */
  .tooltip-container {
    position: relative;
  }

  .custom-tooltip {
    box-shadow: 0 2px 5px rgba(0, 0, 0, 0.2);
    animation: fadeIn 0.2s ease-in-out;
  }

  .tooltip-arrow {
    position: absolute;
    top: 100%;
    left: 10px;
    margin-top: -4px;
    width: 8px;
    height: 8px;
    transform: rotate(45deg);
  }

  @keyframes fadeIn {
    from {
      opacity: 0;
    }
    to {
      opacity: 1;
    }
  }

  .excel-cell-context-selected {
    outline: 2px solid #217346;
    outline-offset: -2px;
    position: relative;
    z-index: 1;
    overflow: visible;
  }

  .context-menu {
    transform: translateY(-100%); /* Move menu up by its own height */
    pointer-events: auto; /* Ensure menu remains interactive */
  }

  /* small arrow */
  .context-menu::before {
    content: '';
    position: absolute;
    top: -5px; /* Change from bottom to top */
    left: 10px;
    width: 0;
    height: 0;
    border-left: 5px solid transparent;
    border-right: 5px solid transparent;
    border-bottom: 5px solid white; /* Change from border-top to border-bottom */
    filter: drop-shadow(0 -1px 1px rgba(0, 0, 0, 0.1)); /* Adjust shadow direction */
  }

  /* --- Style Section (From old_codes.txt, using <style scoped>) --- */
  .selected-row {
    outline: 2px solid #2196f3; /* [cite: 84] */
    border: 2px solid #2196f3; /* [cite: 85] */
    outline-offset: -1px;
    position: relative;
  }

  .bg-red-100 {
    /* Style for pending delete row */
    outline: none !important; /* [cite: 85] */
  }

  /* Excel-inspired container */
  .excel-container {
    font-family: 'Segoe UI', Arial, sans-serif; /* [cite: 86] */
    border: 1px solid #d4d4d8; /* [cite: 86] */
    box-shadow: 0 2px 5px rgba(0, 0, 0, 0.05); /* [cite: 87] */
    border-radius: 2px;
    background-color: #ffffff; /* [cite: 87] */
  }

  /* Excel table styling */
  .excel-table {
    table-layout: fixed; /* [cite: 88] */
    min-width: fit-content; /* [cite: 88] */
    border-collapse: collapse; /* Add this */
  }

  /* Excel header row */
  .excel-header-row {
    background-color: #f3f3f3; /* [cite: 88] */
  }

  /* Excel column headers */
  .excel-column-header {
    background-color: #f3f3f3; /* [cite: 89] */
    border: 1px solid #d0d0d0; /* [cite: 89] */
    padding: 6px 8px; /* [cite: 89] */
    font-weight: 600; /* [cite: 89] */
    font-size: 14px; /* [cite: 89] */
    color: #000000; /* [cite: 90] */
    position: relative; /* [cite: 90] */
    text-align: left; /* [cite: 90] */
    height: 32px; /* Added height */
    box-sizing: border-box; /* Added box-sizing */
    vertical-align: middle; /* Center vertically */
  }

  /* Excel column letter headers (A, B, C) */
  .excel-column-letter {
    background-color: #e6e6e6; /* [cite: 90] */
    border: 1px solid #d0d0d0; /* [cite: 91] */
    padding: 4px 8px; /* [cite: 91] */
    font-weight: 600; /* [cite: 91] */
    font-size: 14px; /* [cite: 91] */
    color: #616161; /* [cite: 91] */
    text-align: center; /* [cite: 91] */
    height: 28px; /* Added height */
    box-sizing: border-box; /* Added box-sizing */
    vertical-align: middle; /* Center vertically */
  }

  /* Update sticky positioning for new column */
  .excel-column-checkbox-selector {
    position: sticky; /* [cite: 92] */
    left: 0; /* [cite: 92] */
    z-index: 5; /* [cite: 92] */
    background-color: #f3f3f3; /* [cite: 92] */ /* Match header */
    border: 1px solid #d0d0d0; /* Added border */
    text-align: center; /* Center checkbox */
    vertical-align: middle; /* Center checkbox */
    box-sizing: border-box;
  }
  /* Need background for sticky cells in body */
  .excel-data-row .excel-column-checkbox-selector {
    background-color: #ffffff; /* White for data rows */
  }
  .excel-data-row:hover .excel-column-checkbox-selector {
    background-color: #edf5fd; /* Match row hover */
  }
  .excel-data-row.selected-row .excel-column-checkbox-selector {
    background-color: #ebf8ff; /* Match selected row (adjust color) */
  }
  .excel-data-row.bg-red-100 .excel-column-checkbox-selector {
    background-color: #fee2e2; /* Match delete row */
  }

  /* Adjust row number positioning */
  .excel-row-number-header {
    /* Applied to TH */
    position: sticky; /* [cite: 98, 100] */
    left: 40px; /* [cite: 98, 101] */ /* Match selector width */
    z-index: 4; /* [cite: 99, 101] */
    background-color: #f3f3f3; /* [cite: 99, 101] */
    border: 1px solid #d0d0d0; /* [cite: 100, 102] */
    /* outline: 1px solid #d0d0d0; */ /* [cite: 100, 103] Outline removed, use border */
    text-align: center; /* Center text */
    vertical-align: middle; /* Center text */
    box-sizing: border-box;
    width: 30px !important; /* [cite: 124] */
    min-width: 30px !important; /* [cite: 124] */
    max-width: 30px !important; /* [cite: 124] */
    padding: 6px 0px; /* Adjust padding */
    font-weight: 600; /* [cite: 97] */
    font-size: 14px; /* [cite: 97] */
    color: #616161; /* [cite: 97] */
  }
  .excel-row-number {
    /* Applied to TD */
    position: sticky; /* [cite: 104] */
    left: 40px; /* [cite: 104] */ /* Match selector width */
    z-index: 2; /* [cite: 105] */
    background-color: #f3f3f3; /* [cite: 105] */
    border: 1px solid #d0d0d0; /* [cite: 105] */
    /* outline: 1px solid #d0d0d0; */ /* [cite: 106] Outline removed, use border */
    text-align: center;
    vertical-align: middle;
    box-sizing: border-box;
    width: 30px !important; /* [cite: 124] */
    min-width: 30px !important; /* [cite: 124] */
    max-width: 30px !important; /* [cite: 124] */
    font-size: 14px; /* Match headers */
    color: #616161; /* Match headers */
  }
  /* Hover state for row numbers */
  .excel-data-row:hover .excel-row-number {
    background-color: #edf5fd; /* [cite: 140] */ /* Match row hover color */
  }
  .excel-data-row.selected-row .excel-row-number {
    background-color: #ebf8ff; /* Match selected row (adjust color) */
  }
  .excel-data-row.bg-red-100 .excel-row-number {
    background-color: #fee2e2; /* Match delete row */
  }

  /* Original selector column TH style (no longer needed?) */
  /* .excel-column-checkbox {
  position: sticky; [cite: 95]
  left: 40px; [cite: 95]
  z-index: 4; [cite: 95]
  background-color: #e6e6e6; [cite: 96]
  border: 1px solid #d0d0d0; [cite: 96]
  padding: 4px 8px; [cite: 96]
  font-weight: 600; [cite: 97]
  font-size: 14px; [cite: 97]
  color: #616161; [cite: 97]
  text-align: center; [cite: 97]
  outline: 1px solid #d0d0d0; [cite: 97]
} */

  .excel-letter {
    font-weight: 700; /* [cite: 97] */
  }

  /* Excel actions header */
  .excel-actions-header {
    /* Applied to TH */
    background-color: #f3f3f3; /* [cite: 106] */
    border: 1px solid #d0d0d0; /* [cite: 106] */
    text-align: center; /* [cite: 106] */
    position: sticky; /* Added sticky */
    right: 0; /* Added sticky */
    z-index: 4; /* Added sticky */
    width: 60px !important; /* [cite: 125] */
    min-width: 60px !important; /* [cite: 125] */
    max-width: 60px !important; /* [cite: 125] */
    box-sizing: border-box;
    vertical-align: middle;
  }
  .excel-actions-cell {
    /* Applied to TD */
    border: 1px solid #d0d0d0;
    position: sticky; /* Added sticky */
    right: 0; /* Added sticky */
    z-index: 2; /* Added sticky */
    width: 60px !important; /* [cite: 125] */
    min-width: 60px !important; /* [cite: 125] */
    max-width: 60px !important; /* [cite: 125] */
    background-color: #ffffff; /* Need background for sticky */
    text-align: center;
    vertical-align: middle;
    box-sizing: border-box;
  }
  /* Hover/Selected states for actions cell */
  .excel-data-row:hover .excel-actions-cell {
    background-color: #edf5fd; /* Match row hover */
  }
  .excel-data-row.selected-row .excel-actions-cell {
    background-color: #ebf8ff; /* Match selected row (adjust color) */
  }
  .excel-data-row.bg-red-100 .excel-actions-cell {
    background-color: #fee2e2; /* Match delete row */
  }

  /* Excel data rows */
  .excel-data-row:hover {
    background-color: #edf5fd; /* [cite: 107] */
  }

  /* Excel data cell */
  .excel-cell {
    border: 1px solid #d0d0d0; /* [cite: 107] */
    padding: 0; /* [cite: 108] */ /* Reset padding for inputs */
    font-size: 14px; /* [cite: 108] */
    color: #212121; /* [cite: 108] */
    position: relative; /* [cite: 108] */
    height: 40px; /* [cite: 108, 116] */ /* Set consistent height */
    box-sizing: border-box; /* Add box-sizing */
    vertical-align: middle; /* Center content */
    overflow: hidden; /* Hide overflow */
    white-space: nowrap; /* Prevent wrapping */
    text-overflow: ellipsis; /* Add ellipsis */
  }
  .excel-cell div {
    /* Ensure divs within cells allow vertical centering */
    display: flex;
    align-items: center;
    height: 100%;
  }

  /* Excel cell content */
  .excel-cell-content {
    padding: 6px 8px; /* [cite: 109] */ /* Restore padding for read-only */
    min-height: 40px; /* [cite: 109] */
    width: 100%; /* Ensure it fills cell */
    overflow: hidden;
    white-space: nowrap;
    text-overflow: ellipsis;
    display: block; /* Override flex from div rule */
  }

  /* Excel cell editable */
  .excel-cell-editable {
    cursor: pointer; /* [cite: 110] */
  }

  .excel-cell-editable:hover {
    background-color: #e8f3fd; /* [cite: 110] */
  }

  /* Excel cell readonly */
  .excel-cell-readonly {
    cursor: not-allowed; /* [cite: 111] */
    opacity: 0.8; /* [cite: 111] */
    background-color: #f9f9f9; /* [cite: 111] */
  }

  /* Excel cell selected - active cell styling */
  .excel-cell-selected {
    outline: 2px solid #217346; /* [cite: 112] */
    outline-offset: -2px; /* [cite: 112] */
    position: relative; /* [cite: 112] */
    z-index: 1; /* [cite: 113] */
    overflow: visible; /* Allow input to overflow slightly if needed */
  }

  /* Excel textarea */
  .excel-textarea {
    width: 100%; /* [cite: 113] */
    height: 100%; /* [cite: 113] */
    padding: 6px 8px; /* [cite: 113] */
    font-family: 'Segoe UI', Arial, sans-serif; /* [cite: 113] */
    font-size: 14px; /* [cite: 114] */
    border: none; /* [cite: 114] */
    resize: none; /* [cite: 114] */
    min-height: 40px; /* [cite: 114] */
    outline: none; /* [cite: 115] */
    box-shadow: none; /* [cite: 115] */
    overflow: hidden; /* [cite: 115] */
    box-sizing: border-box; /* Added */
    background-color: white; /* Ensure background */
    vertical-align: top; /* Align text top */
  }

  /* Excel input */
  .excel-input {
    height: 100%; /* [cite: 118] */
    width: 100%; /* Added */
    min-height: 32px; /* [cite: 118] */ /* Ensure min height */
    border-radius: 0; /* [cite: 118] */
    border: none; /* [cite: 119] */
    box-shadow: none; /* [cite: 119] */
    font-size: 14px; /* [cite: 119] */
    padding: 4px 6px; /* [cite: 119] */
    outline: none; /* Added */
    box-sizing: border-box; /* Added */
    background-color: white; /* Ensure background */
  }

  .excel-input:focus-visible {
    outline: none; /* [cite: 119] */
    box-shadow: none; /* [cite: 120] */
    border: none; /* [cite: 120] */
    /* ring: none; */ /* [cite: 120] */ /* Removed ring */
  }

  /* Excel date input */
  .excel-date-input {
    padding: 2px 4px; /* [cite: 120] */
    font-size: 14px; /* [cite: 120] */
  }

  /* Excel checkbox */
  .excel-checkbox {
    height: 16px; /* [cite: 120] */
    width: 16px; /* [cite: 121] */
    cursor: pointer; /* [cite: 121] */
    accent-color: #217346; /* [cite: 121] */
    vertical-align: middle; /* Align checkbox */
  }

  /* Excel reference value */
  .excel-reference-value {
    color: #0066cc; /* [cite: 121] */
    cursor: pointer; /* [cite: 121] */
    text-decoration: underline; /* Added underline */
  }

  /* Excel timestamp value */
  .excel-timestamp {
    color: #666666; /* [cite: 122] */
    font-style: italic; /* [cite: 122] */
    font-size: 12px; /* [cite: 122] */ /* Slightly smaller */
    display: block; /* Ensure it takes space */
    line-height: normal; /* Reset line height */
  }

  /* Excel auto ID */
  .excel-auto-id {
    color: #888888; /* [cite: 123] */
    font-style: italic; /* [cite: 123] */
    padding: 0 8px; /* [cite: 123] */
    font-size: 12px; /* [cite: 123] */ /* Slightly smaller */
    display: block;
    line-height: normal;
  }

  /* Excel new row */
  .excel-new-row {
    background-color: #e8f5e9; /* [cite: 126] */
  }
  .excel-new-row .excel-cell {
    height: 40px; /* [cite: 116] */
    overflow: visible; /* [cite: 116] */ /* Allow select dropdown */
    vertical-align: middle; /* Center vertically */
  }
  .excel-new-row .excel-input {
    overflow: hidden; /* [cite: 117] */
    height: 100%; /* Ensure input fills cell */
    background-color: white;
    border: 1px solid #d0d0d0; /* Add border for clarity */
  }
  .excel-new-row .excel-select > button {
    /* Target trigger */
    height: 100%;
    background-color: white;
    border: 1px solid #d0d0d0;
  }

  /* Excel cancel button (if used) */
  .excel-cancel-button {
    color: #666666; /* [cite: 126] */
    font-size: 14px; /* [cite: 126] */
    height: 28px; /* [cite: 127] */
  }

  /* Excel add row */
  .excel-add-row {
    cursor: pointer; /* [cite: 127] */
  }

  .excel-add-row:hover {
    background-color: #f0f8ff; /* [cite: 127] */
  }

  /* Excel add cell */
  .excel-add-cell {
    text-align: left; /* [cite: 128] */ /* Changed from center */
    padding: 8px 8px; /* [cite: 128] */ /* Adjusted padding */
    border-top: 1px solid #d0d0d0; /* Add border */
  }

  /* Excel add button */
  .excel-add-button {
    color: #217346; /* [cite: 129] */
    font-weight: 500; /* [cite: 129] */
  }

  /* Excel column resizer */
  .excel-resizer {
    width: 5px; /* [cite: 129] */
    height: 100%; /* [cite: 130] */
    cursor: col-resize; /* [cite: 130] */
    position: absolute; /* [cite: 130] */
    right: 0; /* [cite: 130] */
    top: 0; /* [cite: 130] */
    background-color: transparent; /* [cite: 130] */
    z-index: 10; /* Ensure above cell content */
  }

  .excel-resizer:hover {
    background-color: #93c5fd; /* [cite: 130] */ /* Lighter blue */
  }

  .excel-resizer-active {
    background-color: #3b82f6 !important; /* [cite: 131] */ /* Brighter blue */
  }

  /* Excel select */
  .excel-select {
    font-size: 14px; /* [cite: 131] */
    width: 100%; /* Ensure select fills space */
  }
  /* Style trigger specifically */
  .excel-select > button {
    height: 100%;
    border-radius: 0;
    border: none; /* Remove trigger border in view mode */
    padding: 6px 8px;
    box-sizing: border-box;
    justify-content: space-between; /* Align icon right */
    background-color: transparent;
  }
  .excel-cell-selected .excel-select > button {
    border: 2px solid #217346; /* Add border only when selected */
    background-color: white;
  }

  /* Excel pagination */
  .excel-pagination {
    margin-top: 16px; /* [cite: 133] */
    padding: 8px; /* [cite: 133] */
    border-top: 1px solid #e0e0e0; /* [cite: 133] */
    display: flex; /* [cite: 133] */
    justify-content: center; /* [cite: 133] */
  }

  .excel-pagination-button {
    color: #217346; /* [cite: 134] */
    /* Add other button styling if needed */
  }

  /* Excel footer */
  .excel-footer {
    display: flex; /* [cite: 134] */
    align-items: center; /* [cite: 134] */
    gap: 16px; /* [cite: 134] */ /* Increased gap */
    padding: 8px 16px; /* [cite: 134] */
    border-top: 1px solid #e0e0e0; /* [cite: 135] */
    background-color: #f9f9f9; /* [cite: 135] */
  }

  .excel-page-size-label {
    font-size: 14px; /* [cite: 135] */
    color: #666666; /* [cite: 135] */
  }

  .excel-page-size-select {
    font-size: 14px; /* [cite: 135] */
  }

  .excel-status-info {
    margin-left: auto; /* [cite: 136] */ /* Push to right */
    font-size: 14px; /* [cite: 136] */
    color: #666666; /* [cite: 136] */
  }

  .error-column-header {
    background-color: #fee2e2 !important; /* [cite: 136] */
    border: 1px solid #ef4444 !important; /* [cite: 136] */ /* Changed border width */
  }

  .error-column-cell {
    /* Applied to TD in add row */
    background-color: #fef2f2 !important; /* [cite: 137] */
    /* Removed border here, applied to input instead */
    /* animation: error-flash 5s; */ /* [cite: 137] */ /* Removed animation */
  }
  .excel-new-row .error-column-cell .excel-input {
    /* Target input in error cell */
    border: 1px solid #ef4444 !important;
    outline: 1px solid #ef4444 !important;
  }

  .excel-new-row-error {
    /* Applied to the TR for adding */
    background-color: #fee2e2 !important; /* [cite: 138] */
    /* animation: error-flash 5s; */ /* [cite: 138] */ /* Removed animation */
  }
  /* Flash effect was removed as it might be jarring */
  /* @keyframes error-flash { ... } */ /**/

  /* Sticky Header Adjustments */
  /* Ensure data headers stay below the numbering column header */
  .excel-column-header {
    position: sticky; /* [cite: 138] */
    top: 28px; /* [cite: 139] */ /* Height of alpha header */
    z-index: 3; /* [cite: 139] */
  }
  /* Adjust z-index for the column letters header */
  .excel-header-row th {
    /* Target TH in alpha row */
    position: sticky;
    top: 0;
    z-index: 5; /* [cite: 139] */
  }
  /* Override z-index for specific sticky headers in alpha row */
  .excel-header-row .excel-column-checkbox-selector {
    z-index: 6;
    background-color: #e6e6e6;
  }
  .excel-header-row .excel-column-checkbox {
    z-index: 5;
    background-color: #e6e6e6;
  } /* Row number in alpha */
  .excel-header-row .excel-actions-header {
    z-index: 5;
    background-color: #e6e6e6;
  }

  /* Add green scrollbar to the table container */
  .table-scroll-container::-webkit-scrollbar {
    height: 12px; /* [cite: 141] */
    width: 12px; /* Added width */
    background-color: #f0fdf4; /* [cite: 141] */
  }

  .table-scroll-container::-webkit-scrollbar-track {
    background: #f0fdf4; /* [cite: 142] */
    border-radius: 6px; /* [cite: 142] */
  }

  .table-scroll-container::-webkit-scrollbar-thumb {
    background: #16a34a; /* [cite: 142] */
    border-radius: 6px; /* [cite: 142] */
    border: 2px solid #f0fdf4; /* [cite: 142] */
  }

  .table-scroll-container::-webkit-scrollbar-thumb:hover {
    background: #22c55e; /* [cite: 143] */
  }

  /* Ensure sticky backgrounds cover content */
  th,
  td {
    background-clip: padding-box; /* Prevents background from going under border */
  }
</style>


// src/store/dataTableStore.ts
import { defineStore } from 'pinia'
import { ref, computed } from 'vue'
import { useToast } from '@/components/ui/toast/use-toast'
import { getApiBaseUrl } from '@/utils/api'
import { documentService } from '@/services/documentService'
const API_BASE = getApiBaseUrl()

// Define the structure of a document (adjust based on your actual data)
interface Document {
  _id: { $oid: string }
  [key: string]: any // Allow other properties
}

// Define the structure for reference options
interface ReferenceOption {
  id: string
  label: string
}

export const useDataTableStore = defineStore('dataTable', () => {
  const { toast } = useToast()

  // --- State ---
  const collectionName = ref<string>('users') // Default collection
  const documents = ref<Document[]>([])
  const collectionSchema = ref<any>({}) // Consider defining a stricter type
  const isLoading = ref<boolean>(false)
  const errorMessage = ref<string>('')
  const pageSize = ref<number>(10)
  const currentPage = ref<number>(1)
  const filterQuery = ref<string>('{}') // Keep filter query local or move if needed globally
  const newDocument = ref<Record<string, any>>({})
  const isAdding = ref<boolean>(false)
  const editingCell = ref<{ rowIndex: number; header: string } | null>(null)
  const editValue = ref<any>('') // Can be string, boolean, etc.
  const isSaving = ref<boolean>(false)
  const selectedRows = ref<Set<string>>(new Set())
  const currentView = ref<string>('empty-or-recovered') // e.g., "all", "archives"
  const pendingDeleteId = ref<string | null>(null)
  const referenceOptions = ref<Record<string, ReferenceOption[]>>({})
  const loadingReferences = ref<Record<string, boolean>>({})
  const collectionsList = ref<string[]>([])
  const errorColumn = ref<string | null>(null) // For highlighting duplicate errors
  const addingRowError = ref<boolean>(false)

  // --- Getters (Computed) ---
  const totalDocuments = computed(() => documents.value.length)
  const totalPages = computed(() => Math.ceil(totalDocuments.value / pageSize.value))

  const paginatedDocuments = computed(() => {
    const start = (currentPage.value - 1) * pageSize.value
    const end = start + pageSize.value
    return documents.value.slice(start, end)
  })

  const tableHeaders = computed(() => {
    if (!collectionSchema.value.properties) return []
    const props = collectionSchema.value.properties
    return Object.keys(props).sort((a, b) => {
      const required = collectionSchema.value.required || []
      if (required.includes(a) && !required.includes(b)) return -1
      if (!required.includes(a) && required.includes(b)) return 1
      // Keep _id first if it exists
      if (a === '_id') return -1
      if (b === '_id') return 1
      return a.localeCompare(b)
    })
  })

  const columnWidths = computed(() => {
    return collectionSchema.value?.ui?.columnWidths || {}
  })

  const allSelected = computed({
    get: () => totalDocuments.value > 0 && selectedRows.value.size === totalDocuments.value,
    set: (val: boolean) => {
      selectedRows.value = val ? new Set(documents.value.map((doc) => doc._id.$oid)) : new Set()
    },
  })

  // --- Actions ---

  // Helper to get schema info
  const getSchemaInfo = (field: string) => {
    return collectionSchema.value.properties?.[field] || {}
  }

  // Helper to check if field is reference
  const isReferenceField = (field: string): boolean => {
    return getSchemaInfo(field).description?.includes('REF:') || false
  }

  // Helper to get referenced collection name
  const getReferencedCollection = (field: string): string | null => {
    const desc = getSchemaInfo(field).description || ''
    const match = desc.match(/REF:(\w+)/)
    return match ? match[1] : null
  }

  // Fetch list of collections
  async function fetchCollections() {
    try {
      const response = await fetch(`${API_BASE}/collections`)
      if (!response.ok) throw new Error(`HTTP error! status: ${response.status}`)
      const { success, data, error } = await response.json()
      if (success) {
        collectionsList.value = data
        // Optionally set collectionName if current is invalid or empty
        if (data.length > 0 && (!collectionName.value || !data.includes(collectionName.value))) {
          // await setCollection(data[0]); // Uncomment if you want to auto-select
        }
      } else {
        throw new Error(error || 'Failed to fetch collections')
      }
    } catch (err: any) {
      errorMessage.value = `Error fetching collections: ${err.message}`
      console.error(err)
    }
  }

  // Set the current collection and fetch its data
  async function setCollection(name: string) {
    if (collectionName.value === name && documents.value.length > 0) return // Avoid refetch if already set

    console.log(`Setting collection to: ${name}`)
    collectionName.value = name
    // Reset state for the new collection
    documents.value = []
    collectionSchema.value = {}
    currentPage.value = 1
    selectedRows.value = new Set()
    editingCell.value = null
    isAdding.value = false
    errorMessage.value = ''
    referenceOptions.value = {} // Clear old references

    await fetchSchema() // Fetch schema first
    await fetchDocuments() // Then fetch documents
    await preloadReferenceOptions() // Preload references needed by the schema
  }

  const pinDocument = async (documentId: string) => {
    if (!collectionName.value) {
      console.warn('pinDocument: No collection name provided')
      return
    }

    console.log(
      `pinDocument: Attempting to pin document ${documentId} in collection ${collectionName.value}`
    )

    try {
      console.log(
        `pinDocument: Calling documentService.pinDocument(${collectionName.value}, ${documentId})`
      )
      const response = await documentService.pinDocument(collectionName.value, documentId)
      console.log('pinDocument: Received response', response)

      if (response.success) {
        // Find and replace the document with the updated version from the response
        const updatedDoc = response.data
        const index = documents.value.findIndex((doc) => doc._id.$oid === documentId)
        console.log(`pinDocument: Document index in array: ${index}`)

        if (index !== -1) {
          console.log(`pinDocument: Updating document in local state with response data`)
          documents.value[index] = updatedDoc
        } else {
          console.warn(`pinDocument: Document with ID ${documentId} not found in local state`)
          // If not found, add to documents array (might be a new pinned document)
          console.log(`pinDocument: Adding new document to local state`)
          documents.value.push(updatedDoc)
        }

        // Force array update for Vue reactivity
        console.log(`pinDocument: Forcing array update for Vue reactivity`)
        documents.value = [...documents.value]

        toast({ title: 'Pinned', description: 'Document pinned successfully' })
      } else {
        console.error(`pinDocument: API returned success=false`, response.error)
        errorMessage.value = `Error pinning document: ${response.error}`
        toast({ title: 'Pin Error', description: errorMessage.value, variant: 'destructive' })
      }
    } catch (err: any) {
      console.error(`pinDocument: Exception occurred`, err)
      errorMessage.value = `Error pinning document: ${err.message}`
      toast({ title: 'Pin Error', description: errorMessage.value, variant: 'destructive' })
    }
  }

  const unpinDocument = async (documentId: string) => {
    if (!collectionName.value) {
      console.warn('unpinDocument: No collection name provided')
      return
    }

    console.log(
      `unpinDocument: Attempting to unpin document ${documentId} in collection ${collectionName.value}`
    )

    try {
      console.log(
        `unpinDocument: Calling documentService.unpinDocument(${collectionName.value}, ${documentId})`
      )
      const response = await documentService.unpinDocument(collectionName.value, documentId)
      console.log('unpinDocument: Received response', response)

      if (response.success) {
        // Find and replace the document with the updated version from the response
        const updatedDoc = response.data
        const index = documents.value.findIndex((doc) => doc._id.$oid === documentId)
        console.log(`unpinDocument: Document index in array: ${index}`)

        if (index !== -1) {
          console.log(`unpinDocument: Updating document in local state with response data`)
          documents.value[index] = updatedDoc
        } else {
          console.warn(`unpinDocument: Document with ID ${documentId} not found in local state`)
        }

        // Force array update for Vue reactivity
        console.log(`unpinDocument: Forcing array update for Vue reactivity`)
        documents.value = [...documents.value]

        toast({ title: 'Unpinned', description: 'Document unpinned successfully' })
      } else {
        console.error(`unpinDocument: API returned success=false`, response.error)
        errorMessage.value = `Error unpinning document: ${response.error}`
        toast({ title: 'Unpin Error', description: errorMessage.value, variant: 'destructive' })
      }
    } catch (err: any) {
      console.error(`unpinDocument: Exception occurred`, err)
      errorMessage.value = `Error unpinning document: ${err.message}`
      toast({ title: 'Unpin Error', description: errorMessage.value, variant: 'destructive' })
    }
  }

  // Fetch schema for the current collection
  async function fetchSchema() {
    if (!collectionName.value) return
    isLoading.value = true // Indicate loading schema
    errorMessage.value = ''
    try {
      // Prefer API fetch if available, fallback to invoke if needed
      const response = await fetch(`${API_BASE}/collections/${collectionName.value}/schema`)
      if (!response.ok) throw new Error(`HTTP error! status: ${response.status}`)
      const { success, data, error } = await response.json()

      if (success) {
        console.log(`Loaded schema for ${collectionName.value}:`, data)
        collectionSchema.value = data
        initializeNewDocument() // Initialize based on new schema
      } else {
        throw new Error(error || 'Schema fetch failed')
      }

      // --- Fallback using invoke (keep if API endpoint isn't ready) ---
      // collectionSchema.value = await invoke('get_collection_schema', {
      //   collectionName: collectionName.value
      // });
      // console.log('Schema fetch successful (invoke):', collectionSchema.value);
      // initializeNewDocument(); // Initialize based on new schema
    } catch (err: any) {
      errorMessage.value = `Schema error: ${err.message}`
      collectionSchema.value = {} // Reset schema on error
      console.error('Schema fetch error:', err)
    } finally {
      isLoading.value = false // Schema loading finished
    }
  }

  // Fetch documents for the current collection and view
  async function fetchDocuments() {
    if (!collectionName.value) return
    isLoading.value = true
    errorMessage.value = ''
    pendingDeleteId.value = null // Clear pending deletion style

    try {
      let filter = {}
      try {
        filter = JSON.parse(filterQuery.value) // Use the filter from state
      } catch (e: any) {
        throw new Error(`Invalid filter JSON: ${e.message}`)
      }

      // Build endpoint based on current view
      let endpoint
      switch (currentView.value) {
        case 'archives':
          endpoint = `${API_BASE}/collections/${collectionName.value}/archives`
          break
        case 'recoveries':
          endpoint = `${API_BASE}/collections/${collectionName.value}/recoveries`
          break
        case 'empty-or-recovered':
          endpoint = `${API_BASE}/collections/${collectionName.value}/empty-or-recovered`
          break
        case 'pins':
          endpoint = `${API_BASE}/collections/${collectionName.value}/pins`
          break
        case 'all':
        default:
          endpoint = `${API_BASE}/collections/${collectionName.value}/documents`
          break
      }

      const params = new URLSearchParams()
      params.append('filter', JSON.stringify(filter))
      // Add pagination/sorting params if your API supports them
      // params.append('page', currentPage.value.toString());
      // params.append('limit', pageSize.value.toString());

      const url = `${endpoint}?${params.toString()}`
      const response = await fetch(url)
      if (!response.ok) throw new Error(`HTTP error! status: ${response.status}`)
      const { success, data, error } = await response.json()

      if (success) {
        documents.value = data
        if (currentPage.value > totalPages.value) {
          currentPage.value = Math.max(1, totalPages.value) // Adjust page if out of bounds
        }
        console.log(`Workspaceed documents for ${currentView.value} view:`, data.length)
      } else {
        throw new Error(error || 'Failed to fetch documents')
      }
    } catch (err: any) {
      errorMessage.value = `Error fetching documents: ${err.message}`
      documents.value = [] // Clear documents on error
      console.error(err)
    } finally {
      isLoading.value = false
    }
  }

  // Preload reference options needed for the current schema
  async function preloadReferenceOptions() {
    if (!collectionSchema.value.properties) return

    const fields = Object.keys(collectionSchema.value.properties)
    for (const field of fields) {
      const refCollection = getReferencedCollection(field)
      if (refCollection && !referenceOptions.value[refCollection]) {
        await fetchReferenceOptions(refCollection)
      }
    }
  }

  // Fetch options for a referenced collection
  async function fetchReferenceOptions(refCollectionName: string, force = false) {
    if (!force && referenceOptions.value[refCollectionName]?.length > 0) {
      console.log(`Using cached options for ${refCollectionName}`)
      return // Already fetched or has data
    }
    if (loadingReferences.value[refCollectionName]) return // Already loading

    loadingReferences.value[refCollectionName] = true
    console.log(`Workspaceing reference options for: ${refCollectionName}`)

    try {
      // 1. Fetch Schema to determine the best label field
      const schemaResponse = await fetch(`${API_BASE}/collections/${refCollectionName}/schema`)
      if (!schemaResponse.ok) throw new Error(`Schema fetch failed for ${refCollectionName}`)
      const {
        success: schemaSuccess,
        data: schemaData,
        error: schemaError,
      } = await schemaResponse.json()
      if (!schemaSuccess)
        throw new Error(schemaError || `Failed to fetch schema for ${refCollectionName}`)

      let labelField = '_id' // Default label
      const properties = schemaData.properties || {}
      const uniqueStringFields = Object.keys(properties).filter(
        (field) => properties[field].bsonType === 'string' && properties[field].unique === true
      )
      if (uniqueStringFields.length > 0) {
        labelField = uniqueStringFields[0] // Prefer unique string fields
      } else {
        const commonLabels = ['label', 'name', 'title', 'username']
        labelField = commonLabels.find((f) => properties[f]?.bsonType === 'string') || '_id'
      }
      console.log(`Using label field '${labelField}' for ${refCollectionName}`)

      // 2. Fetch Documents to populate options
      const docsResponse = await fetch(
        `${API_BASE}/collections/${refCollectionName}/documents?limit=1000`
      ) // Fetch all or limit as needed
      if (!docsResponse.ok) throw new Error(`Document fetch failed for ${refCollectionName}`)
      const { success: docsSuccess, data: docsData, error: docsError } = await docsResponse.json()

      if (docsSuccess) {
        referenceOptions.value[refCollectionName] = docsData.map((doc: any) => ({
          id: doc._id.$oid, // Assuming MongoDB ObjectId structure
          label: doc[labelField] || doc._id.$oid, // Use determined label or fallback to ID
        }))
        console.log(
          `Workspaceed ${referenceOptions.value[refCollectionName].length} options for ${refCollectionName}`
        )
        if (referenceOptions.value[refCollectionName].length === 0) {
          toast({
            title: 'No Reference Options',
            description: `No documents found in collection '${refCollectionName}'.`,
            variant: 'default',
          })
        }
      } else {
        throw new Error(docsError || `Failed to fetch documents for ${refCollectionName}`)
      }
    } catch (err: any) {
      toast({
        title: 'Reference Error',
        description: `Failed to load options for ${refCollectionName}: ${err.message}`,
        variant: 'destructive',
      })
      referenceOptions.value[refCollectionName] = [] // Ensure it's an empty array on error
      console.error(err)
    } finally {
      loadingReferences.value[refCollectionName] = false
    }
  }

  // Get label for a reference ID
  function getReferenceLabel(field: string, id: string): string {
    const refCollection = getReferencedCollection(field)
    if (!refCollection) return id // Not a reference field
    const options = referenceOptions.value[refCollection] || []
    const option = options.find((opt) => opt.id === id)
    return option ? option.label : id // Return label or ID if not found
  }

  // Initialize the new document structure based on schema
  function initializeNewDocument() {
    const doc: Record<string, any> = {}
    const required = collectionSchema.value.required || []
    const properties = collectionSchema.value.properties || {}

    // Initialize required fields first (excluding specific auto-fields)
    required.forEach((field: string) => {
      if (['_id', 'created_at', 'updated_at'].includes(field)) return
      const prop = properties[field]
      if (prop) {
        doc[field] = getDefaultValue(prop.bsonType)
      }
    })

    // Consider adding default values for non-required fields if desired
    // Object.keys(properties).forEach(field => {
    //   if (!doc.hasOwnProperty(field) && !['_id', 'created_at', 'updated_at'].includes(field)) {
    //      doc[field] = getDefaultValue(properties[field].bsonType);
    //   }
    // });

    newDocument.value = doc
    console.log('Initialized new document structure:', newDocument.value)
  }

  // Get default value based on BSON type
  function getDefaultValue(bsonType: string | string[]) {
    const type = Array.isArray(bsonType) ? bsonType[0] : bsonType // Handle potential array of types
    switch (type) {
      case 'string':
        return ''
      case 'int':
      case 'long':
      case 'double':
      case 'decimal':
        return 0
      case 'bool':
        return false
      case 'date':
        return new Date().toISOString() // Store dates consistently, e.g., ISO string
      case 'objectId':
        return null // Or handle differently if needed
      case 'object':
        return {}
      case 'array':
        return []
      default:
        return null
    }
  }

  // Start adding a new document
  function startAdding() {
    initializeNewDocument() // Ensure clean slate based on current schema
    isAdding.value = true
    addingRowError.value = false // Reset error state
    errorColumn.value = null
    // Pre-fetch references needed for the add form
    preloadReferenceOptions()
  }

  // Cancel adding
  function cancelAdding() {
    isAdding.value = false
    newDocument.value = {} // Clear the form
    addingRowError.value = false
    errorColumn.value = null
  }

  // Save the new document
  async function saveNewDocument() {
    if (!collectionName.value) return
    isSaving.value = true // Use isSaving for feedback
    errorMessage.value = ''
    errorColumn.value = null
    addingRowError.value = false

    console.log('Attempting to save new document:', newDocument.value)

    try {
      const response = await fetch(`${API_BASE}/collections/${collectionName.value}/documents`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(newDocument.value),
      })

      // Check if response is OK, even if not strictly JSON (e.g., 201 Created with no body)
      if (!response.ok) {
        // Try to parse error JSON, otherwise use status text
        let errorData
        try {
          errorData = await response.json()
        } catch (jsonError) {
          // Ignore json parse error if body is not json
        }
        const errorDetail = errorData?.error || `HTTP ${response.status}: ${response.statusText}`
        throw new Error(errorDetail)
      }

      // Handle potential non-JSON success response (like 201)
      let result
      const contentType = response.headers.get('content-type')
      if (contentType && contentType.includes('application/json')) {
        result = await response.json()
      } else {
        // Assume success if response.ok was true and no JSON body
        result = { success: true }
      }

      // Check application-level success (if applicable)
      if (result.success) {
        toast({ title: 'Success', description: 'Document created successfully.' })
        isAdding.value = false
        await fetchDocuments() // Refresh list
      } else {
        // This else block might be redundant if !response.ok is handled above,
        // but keep it if your API returns 200 OK with a success: false payload
        throw new Error(result.error || 'Failed to create document (API indicated failure)')
      }
    } catch (err: any) {
      console.error('Save new document error:', err)
      errorMessage.value = err.message || 'Failed to create document'
      addingRowError.value = true // Indicate error on the add row

      // Handle specific errors like duplicates
      if (err.message && err.message.includes('E11000')) {
        // Extract field name from duplicate key error message
        const fieldMatch = err.message.match(/index: (\w+)_/) // Basic pattern, adjust if needed
        const valueMatch = err.message.match(/dup key: { (\w+): "(.+?)" }/) // More specific pattern
        const fieldName = valueMatch ? valueMatch[1] : fieldMatch ? fieldMatch[1] : null

        if (fieldName) {
          errorMessage.value = `Duplicate value detected for field "${fieldName}". Please use a unique value.`
          errorColumn.value = fieldName // Highlight the column in the add row
        } else {
          errorMessage.value = 'Duplicate value detected. Please check unique fields.'
        }
      }

      // Optionally use toast for errors too
      toast({ title: 'Save Error', description: errorMessage.value, variant: 'destructive' })
    } finally {
      isSaving.value = false
    }
  }

  // Start editing a cell
  function startEditingCell(rowIndex: number, header: string, currentValue: any) {
    if (isSaving.value) return // Don't allow edit while saving
    if (['_id', 'created_at', 'updated_at'].includes(header)) return // Non-editable fields

    // Commit previous edit if any
    if (editingCell.value) {
      // Consider auto-saving on blur/new cell click, or require explicit save
      // For simplicity here, we just cancel the previous edit visually
      // await saveEdit(); // Uncomment if you want to auto-save previous cell
    }

    const doc = paginatedDocuments.value[rowIndex]
    if (!doc) return

    editingCell.value = { rowIndex, header }

    // Format value for editing input
    const schemaInfo = getSchemaInfo(header)
    const bsonType = Array.isArray(schemaInfo.bsonType)
      ? schemaInfo.bsonType[0]
      : schemaInfo.bsonType

    if (bsonType === 'bool') {
      editValue.value = !!currentValue // Ensure boolean
    } else if (bsonType === 'date') {
      // Ensure date is in YYYY-MM-DDTHH:mm format for datetime-local input
      editValue.value = currentValue ? new Date(currentValue).toISOString().slice(0, 16) : ''
    } else if (isReferenceField(header)) {
      editValue.value = currentValue || '' // Store the ID for the select
      // Ensure options are loaded for the reference field
      const refCollection = getReferencedCollection(header)
      if (refCollection) {
        fetchReferenceOptions(refCollection)
      }
    } else if (typeof currentValue === 'object' && currentValue !== null) {
      editValue.value = JSON.stringify(currentValue, null, 2) // Pretty print objects/arrays
    } else {
      editValue.value = String(currentValue ?? '') // Handle null/undefined
    }

    console.log(`Start editing: Row ${rowIndex}, Header ${header}, Value:`, editValue.value)
  }

  // Cancel editing a cell
  function cancelEdit() {
    editingCell.value = null
    editValue.value = ''
  }

  function updateDocument(docId: string, updatedDoc: any) {
    console.log(`Updating document ${docId} in store:`, updatedDoc)

    // Find document index in the main documents array
    const docIndex = documents.value.findIndex((doc) => doc._id.$oid === docId)

    if (docIndex !== -1) {
      // Replace the document with the updated version
      documents.value = documents.value.map((doc, index) => (index === docIndex ? updatedDoc : doc))

      console.log(`Document updated successfully at index ${docIndex}`)
      // No need to update paginatedDocuments as it's a computed property
      // that will automatically update based on the documents array
    } else {
      console.warn(`Document with ID ${docId} not found in local state`)
    }
  }

  // Save an edited cell value
  async function saveEdit() {
    if (!editingCell.value || isSaving.value) return

    const { rowIndex, header } = editingCell.value
    const doc = paginatedDocuments.value[rowIndex]
    if (!doc) {
      cancelEdit()
      return
    }

    const docId = doc._id.$oid
    isSaving.value = true
    errorMessage.value = ''
    const originalValue = doc[header] // Store original value for comparison/revert

    try {
      let valueToSave: any
      const schemaInfo = getSchemaInfo(header)
      const bsonType = Array.isArray(schemaInfo.bsonType)
        ? schemaInfo.bsonType[0]
        : schemaInfo.bsonType

      // --- Parse/Validate editValue based on type ---
      if (isReferenceField(header)) {
        valueToSave = editValue.value // Assume editValue holds the selected ID string
      } else if (bsonType === 'bool') {
        valueToSave = Boolean(editValue.value)
      } else if (bsonType === 'date') {
        valueToSave = editValue.value ? new Date(editValue.value).toISOString() : null
      } else if (['int', 'long'].includes(bsonType)) {
        valueToSave = parseInt(editValue.value, 10)
        if (isNaN(valueToSave)) throw new Error('Invalid integer value')
      } else if (['double', 'decimal'].includes(bsonType)) {
        valueToSave = parseFloat(editValue.value)
        if (isNaN(valueToSave)) throw new Error('Invalid number value')
      } else if (bsonType === 'string') {
        valueToSave = editValue.value // Keep as string
      } else if (bsonType === 'object' || bsonType === 'array') {
        try {
          valueToSave = JSON.parse(editValue.value)
        } catch (e) {
          throw new Error('Invalid JSON format')
        }
      } else {
        valueToSave = editValue.value // Default case
      }

      // --- Check if value actually changed ---
      // Note: Deep comparison might be needed for objects/arrays if stringify isn't sufficient
      if (JSON.stringify(valueToSave) === JSON.stringify(originalValue)) {
        console.log('No changes detected, skipping save.')
        cancelEdit() // Exit edit mode
        return
      }

      console.log(`Saving edit for Doc ID: ${docId}, Header: ${header}, New Value:`, valueToSave)

      const update = { [header]: valueToSave }
      const response = await fetch(
        `${API_BASE}/collections/${collectionName.value}/documents/${docId}`,
        {
          method: 'PUT',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify(update),
        }
      )

      if (!response.ok) {
        let errorData
        try {
          errorData = await response.json()
        } catch {
          /* ignore */
        }
        throw new Error(errorData?.error || `Update failed: HTTP ${response.status}`)
      }

      const result = await response.json()

      if (result.success && result.data?.document) {
        const updatedDoc = result.data.document

        // Update the document in the store - this will automatically update any computed properties
        // using the proper store action instead of direct mutation
        updateDocument(docId, updatedDoc)

        toast({ title: 'Update Successful', description: `Field '${header}' updated.` })
        cancelEdit() // Exit edit mode on success
      } else if (result.success && result.data?.modified_count === 0) {
        // API succeeded but didn't modify (e.g., value was the same)
        console.log('Update sent, but no changes made in DB.')
        cancelEdit()
      } else {
        throw new Error(result.error || 'Update failed (API indicated failure)')
      }
    } catch (err: any) {
      errorMessage.value = `Error updating field '${header}': ${err.message}`
      toast({ title: 'Update Error', description: errorMessage.value, variant: 'destructive' })
      console.error('Save edit error:', err)
    } finally {
      isSaving.value = false
    }
  }

  // Delete a document
  async function deleteDocument(docId: string) {
    if (!collectionName.value) return
    pendingDeleteId.value = docId // Style the row during delete attempt
    errorMessage.value = ''

    try {
      const response = await fetch(
        `${API_BASE}/collections/${collectionName.value}/documents/${docId}`,
        { method: 'DELETE' }
      )

      if (!response.ok) {
        let errorData
        try {
          errorData = await response.json()
        } catch {
          /* ignore */
        }
        throw new Error(errorData?.error || `Delete failed: HTTP ${response.status}`)
      }

      // Check response body if API confirms success
      const result = await response.json() // Or handle non-JSON responses if applicable

      if (result.success) {
        // Adjust based on your API response structure
        toast({ title: 'Document Deleted', description: `Document ID: ${docId} deleted.` })
        // Remove from local state *after* successful deletion
        documents.value = documents.value.filter((doc) => doc._id.$oid !== docId)
        selectedRows.value.delete(docId) // Remove from selection if present
      } else {
        throw new Error(result.error || 'Delete failed (API indicated failure)')
      }
    } catch (err: any) {
      errorMessage.value = `Error deleting document ${docId}: ${err.message}`
      toast({ title: 'Delete Error', description: errorMessage.value, variant: 'destructive' })
      console.error(err)
    } finally {
      // Clear pending style regardless of success/failure *after* potential fetchDocuments
      // If fetchDocuments is called on success, it resets loading and pending ID
      if (errorMessage.value) {
        // Only clear if there was an error (success clears via fetch)
        pendingDeleteId.value = null
      }
      // Consider calling fetchDocuments() here instead of filtering locally
      // await fetchDocuments(); // This ensures consistency with the backend
    }
  }

  // Toggle row selection
  function toggleRow(id: string) {
    const newSet = new Set(selectedRows.value)
    if (newSet.has(id)) {
      newSet.delete(id)
    } else {
      newSet.add(id)
    }
    selectedRows.value = newSet // Assign new Set to trigger reactivity
    // Optional toast notification removed for brevity, add back if desired
  }

  // Reset selection
  function resetSelection() {
    selectedRows.value = new Set()
    editingCell.value = null // Also cancel any active edit
  }

  // Change the current view (all, archives, etc.)
  function changeView(view: string) {
    if (currentView.value !== view) {
      currentView.value = view
      currentPage.value = 1 // Reset to first page on view change
      fetchDocuments() // Refetch documents for the new view
    }
  }

  // Set current page
  function setPage(page: number) {
    const newPage = Math.max(1, Math.min(page, totalPages.value))
    if (currentPage.value !== newPage) {
      currentPage.value = newPage
      // Fetching might not be needed if pagination is purely client-side
      // If API supports server-side pagination, call fetchDocuments() here
    }
  }

  // Set page size
  function setPageSize(size: number) {
    pageSize.value = size
    currentPage.value = 1 // Reset to page 1 when size changes
    // Fetching might not be needed if pagination is purely client-side
    // If API supports server-side pagination, call fetchDocuments() here
  }

  async function updateDocumentField(documentId: string, field: string, value: any) {
    if (!collectionName.value) return

    errorMessage.value = ''
    console.log(`Updating document ${documentId}, field ${field} to:`, value)

    try {
      const update = { [field]: value }
      const response = await fetch(
        `${API_BASE}/collections/${collectionName.value}/documents/${documentId}`,
        {
          method: 'PUT',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify(update),
        }
      )

      if (!response.ok) {
        let errorData
        try {
          errorData = await response.json()
        } catch {
          /* ignore */
        }
        throw new Error(errorData?.error || `Update failed: HTTP ${response.status}`)
      }

      const result = await response.json()

      if (result.success) {
        // Update local document state
        const docIndex = documents.value.findIndex((d) => d._id.$oid === documentId)
        if (docIndex !== -1) {
          documents.value[docIndex] = { ...documents.value[docIndex], ...update }
          // Force reactivity update
          documents.value = [...documents.value]
        }
        return true
      } else {
        throw new Error(result.error || 'Update failed (API indicated failure)')
      }
    } catch (err: any) {
      errorMessage.value = `Error updating field '${field}': ${err.message}`
      toast({ title: 'Update Error', description: errorMessage.value, variant: 'destructive' })
      console.error('Update document field error:', err)
      return false
    }
  }

  // Update and save column widths
  async function updateColumnWidth(header: string, width: number) {
    if (!collectionSchema.value.ui) {
      collectionSchema.value.ui = {}
    }
    if (!collectionSchema.value.ui.columnWidths) {
      collectionSchema.value.ui.columnWidths = {}
    }
    // Update local schema immediately for responsiveness
    collectionSchema.value.ui.columnWidths = {
      ...collectionSchema.value.ui.columnWidths,
      [header]: Math.max(50, width), // Ensure minimum width
    }
    // Debounced save to backend will be handled in the component using this action
    await saveColumnWidthsToBackend()
  }

  // Reset a specific column width
  async function resetColumnWidth(header: string) {
    if (collectionSchema.value?.ui?.columnWidths?.[header]) {
      const newWidths = { ...collectionSchema.value.ui.columnWidths }
      delete newWidths[header]
      collectionSchema.value.ui.columnWidths = newWidths
      await saveColumnWidthsToBackend()
    }
  }

  // Save column widths to backend (called by debounced function in component)
  async function saveColumnWidthsToBackend() {
    if (!collectionName.value) return
    console.log('Saving column widths to backend:', columnWidths.value)
    try {
      const response = await fetch(`${API_BASE}/collections/${collectionName.value}/ui-metadata`, {
        method: 'PUT',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ columnWidths: columnWidths.value }),
      })
      if (!response.ok) {
        let errorData
        try {
          errorData = await response.json()
        } catch {
          /* ignore */
        }
        throw new Error(errorData?.error || `Save widths failed: HTTP ${response.status}`)
      }
      const result = await response.json()
      if (result.success) {
        console.log('Column widths saved successfully.')
        // Optionally show a success toast
      } else {
        throw new Error(result.error || 'Failed to save column widths (API Error)')
      }
    } catch (err: any) {
      toast({
        title: 'Save Error',
        description: `Could not save column widths: ${err.message}`,
        variant: 'destructive',
      })
      console.error('Error saving column widths:', err)
    }
  }

  // Clear error message
  function clearError() {
    errorMessage.value = ''
  }

  // Return state, getters, and actions
  return {
    // State
    collectionName,
    documents,
    collectionSchema,
    isLoading,
    errorMessage,
    pageSize,
    currentPage,
    filterQuery, // Keep filter local to component or move here if needed globally
    newDocument,
    isAdding,
    editingCell,
    editValue,
    isSaving,
    selectedRows,
    currentView,
    pendingDeleteId,
    referenceOptions,
    loadingReferences,
    collectionsList,
    errorColumn,
    addingRowError,

    // Getters
    totalDocuments,
    totalPages,
    paginatedDocuments,
    tableHeaders,
    columnWidths,
    allSelected,

    // Actions
    fetchCollections,
    setCollection,
    fetchSchema, // Expose if needed externally, otherwise internal use
    fetchDocuments,
    fetchReferenceOptions,
    getReferenceLabel,
    initializeNewDocument, // Might be internal unless needed outside
    startAdding,
    cancelAdding,
    saveNewDocument,
    startEditingCell,
    cancelEdit,
    saveEdit,
    updateDocument,
    deleteDocument,
    toggleRow,
    resetSelection,
    changeView,
    setPage,
    setPageSize,
    updateDocumentField,
    updateColumnWidth,
    resetColumnWidth,
    saveColumnWidthsToBackend, // Exposed for debouncing in component
    clearError,
    getSchemaInfo, // Expose helpers if needed in component template
    isReferenceField,
    getReferencedCollection,
    pinDocument,
    unpinDocument,
  }
})
// src/services/documentService.ts

import { AUTH_CONSTANTS } from '@/constants/auth'
import { getApiBaseUrl } from '@/utils/api'

interface ApiResponse<T> {
  success: boolean
  data?: T
  error?: string
}

export const documentService = {
  // Get the authentication token from localStorage
  getAuthToken(): string | null {
    return localStorage.getItem(AUTH_CONSTANTS.TOKEN_KEY)
  },
  // Create authentication headers for API requests
  getAuthHeaders(): HeadersInit {
    const token = this.getAuthToken()
    if (!token) {
      console.warn('No authentication token available')
      return {
        'Content-Type': 'application/json',
      }
    }

    return {
      'Content-Type': 'application/json',
      Authorization: `${AUTH_CONSTANTS.TOKEN_PREFIX} ${token}`,
    }
  },

  async fetchCollections(): Promise<ApiResponse<string[]>> {
    try {
      const response = await fetch(`${getApiBaseUrl()}/collections`)

      if (!response.ok) {
        throw new Error(`API returned ${response.status}: ${response.statusText}`)
      }

      return (await response.json()) as ApiResponse<string[]>
    } catch (error) {
      console.error('Error fetching collections:', error)
      return {
        success: false,
        error: `Failed to load collections: ${error}`,
      }
    }
  },

  async deleteDocument(collectionName: string, documentId: string) {
    const response = await fetch(
      `${getApiBaseUrl()}/collections/${collectionName}/documents/${documentId}`,
      { method: 'DELETE' }
    )
    return response.json()
  },

  // documentService.ts

  async pinDocument(collectionName: string, documentId: string) {
    console.log(
      `documentService.pinDocument: Starting API call for ${collectionName}/${documentId}`
    )
    try {
      const url = `${getApiBaseUrl()}/collections/${collectionName}/documents/${documentId}/pin`
      console.log(`documentService.pinDocument: Sending PUT request to ${url}`)

      const response = await fetch(url, {
        method: 'PUT',
        headers: this.getAuthHeaders(),
      })

      console.log(`documentService.pinDocument: Received response with status ${response.status}`)

      if (!response.ok) {
        console.error(
          `documentService.pinDocument: HTTP error ${response.status}: ${response.statusText}`
        )
      }

      const data = await response.json()
      console.log(`documentService.pinDocument: Parsed response data`, data)
      return data
    } catch (error) {
      console.error('documentService.pinDocument: Error occurred:', error)
      throw error
    }
  },

  async unpinDocument(collectionName: string, documentId: string) {
    console.log(
      `documentService.unpinDocument: Starting API call for ${collectionName}/${documentId}`
    )
    try {
      const url = `${getApiBaseUrl()}/collections/${collectionName}/documents/${documentId}/unpin`
      console.log(`documentService.unpinDocument: Sending PUT request to ${url}`)

      const response = await fetch(url, {
        method: 'PUT',
        headers: this.getAuthHeaders(),
      })

      console.log(`documentService.unpinDocument: Received response with status ${response.status}`)

      if (!response.ok) {
        console.error(
          `documentService.unpinDocument: HTTP error ${response.status}: ${response.statusText}`
        )
      }

      const data = await response.json()
      console.log(`documentService.unpinDocument: Parsed response data`, data)
      return data
    } catch (error) {
      console.error('documentService.unpinDocument: Error occurred:', error)
      throw error
    }
  },
}









